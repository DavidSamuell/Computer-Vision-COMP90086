{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeef3cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import models\n",
    "import random\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(789)\n",
    "np.random.seed(789)\n",
    "random.seed(789)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(789)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f943061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation - Calorie Prediction Only (No Segmentation)\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"ResNet encoder that extracts feature maps\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder_type: str = 'resnet18', pretrained: bool = False, in_channels: int = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load appropriate ResNet\n",
    "        if encoder_type == 'resnet18':\n",
    "            resnet = models.resnet18(pretrained=pretrained)\n",
    "            self.out_channels = 512\n",
    "        elif encoder_type == 'resnet34':\n",
    "            resnet = models.resnet34(pretrained=pretrained)\n",
    "            self.out_channels = 512\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported encoder: {encoder_type}\")\n",
    "        \n",
    "        # Modify first conv if we have different input channels (e.g., 1 for depth)\n",
    "        if in_channels != 3:\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = resnet.conv1\n",
    "        \n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        \n",
    "        # ResNet layers\n",
    "        self.layer1 = resnet.layer1  # Output: 64 channels\n",
    "        self.layer2 = resnet.layer2  # Output: 128 channels\n",
    "        self.layer3 = resnet.layer3  # Output: 256 channels\n",
    "        self.layer4 = resnet.layer4  # Output: 512 channels\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (B, C, H, W)\n",
    "        Returns:\n",
    "            Feature map (B, 512, H/32, W/32)\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class MiddleFusionModule(nn.Module):\n",
    "    \"\"\"Middle fusion: Concatenate RGB and Depth features, then merge with 1x1 conv\"\"\"\n",
    "    \n",
    "    def __init__(self, rgb_channels: int = 512, depth_channels: int = 512, output_channels: int = 512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1x1 convolution to merge features\n",
    "        self.fusion_conv = nn.Conv2d(\n",
    "            rgb_channels + depth_channels,\n",
    "            output_channels,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, rgb_features, depth_features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rgb_features: (B, 512, H, W)\n",
    "            depth_features: (B, 512, H, W)\n",
    "        Returns:\n",
    "            Fused features: (B, 512, H, W)\n",
    "        \"\"\"\n",
    "        # Concatenate along channel dimension\n",
    "        fused = torch.cat([rgb_features, depth_features], dim=1)  # (B, 1024, H, W)\n",
    "        \n",
    "        # Apply 1x1 conv to reduce channels\n",
    "        fused = self.fusion_conv(fused)  # (B, 512, H, W)\n",
    "        fused = self.bn(fused)\n",
    "        fused = self.relu(fused)\n",
    "        \n",
    "        return fused\n",
    "\n",
    "\n",
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, in_channels: int = 512, dropout_rate: float = 0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.avgpool(x)  # (B, C, 1, 1)\n",
    "        x = self.fc_layers(x)  # (B, 1)\n",
    "        return x\n",
    "\n",
    "# Inception Fusion Module\n",
    "class InceptionFusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Inception-style Fusion: Multi-scale processing after concatenation\n",
    "    Applies different kernel sizes in parallel like Inception modules\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rgb_channels: int = 512, depth_channels: int = 512, output_channels: int = 512):\n",
    "        super().__init__()\n",
    "        \n",
    "        concat_channels = rgb_channels + depth_channels\n",
    "        branch_channels = output_channels // 4\n",
    "        \n",
    "        # Branch 1: 1x1 conv\n",
    "        self.branch1x1 = nn.Sequential(\n",
    "            nn.Conv2d(concat_channels, branch_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Branch 2: 1x1 -> 3x3 conv\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            nn.Conv2d(concat_channels, branch_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(branch_channels, branch_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Branch 3: 1x1 -> 5x5 conv (using two 3x3)\n",
    "        self.branch5x5 = nn.Sequential(\n",
    "            nn.Conv2d(concat_channels, branch_channels // 2, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(branch_channels // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(branch_channels // 2, branch_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(branch_channels, branch_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Branch 4: 3x3 max pool -> 1x1 conv\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(concat_channels, branch_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Final adjustment if needed\n",
    "        total_out_channels = branch_channels * 4\n",
    "        if total_out_channels != output_channels:\n",
    "            self.final_conv = nn.Sequential(\n",
    "                nn.Conv2d(total_out_channels, output_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.final_conv = None\n",
    "    \n",
    "    def forward(self, rgb_features, depth_features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rgb_features: (B, C1, H, W)\n",
    "            depth_features: (B, C2, H, W)\n",
    "        Returns:\n",
    "            Fused features: (B, output_channels, H, W)\n",
    "        \"\"\"\n",
    "        # Concatenate first\n",
    "        concatenated = torch.cat([rgb_features, depth_features], dim=1)\n",
    "        \n",
    "        # Process through parallel branches\n",
    "        branch1 = self.branch1x1(concatenated)\n",
    "        branch2 = self.branch3x3(concatenated)\n",
    "        branch3 = self.branch5x5(concatenated)\n",
    "        branch4 = self.branch_pool(concatenated)\n",
    "        \n",
    "        # Concatenate all branches\n",
    "        fused = torch.cat([branch1, branch2, branch3, branch4], dim=1)\n",
    "        \n",
    "        # Final adjustment if needed\n",
    "        if self.final_conv is not None:\n",
    "            fused = self.final_conv(fused)\n",
    "        \n",
    "        return fused\n",
    "\n",
    "# Fusion factory function\n",
    "def get_fusion_module(fusion_name, rgb_channels, depth_channels, output_channels):\n",
    "    \"\"\"\n",
    "    Factory function to get fusion module\n",
    "    \n",
    "    Args:\n",
    "        fusion_name: Name of fusion module ('middle' or 'inception')\n",
    "        rgb_channels: Number of RGB feature channels\n",
    "        depth_channels: Number of depth feature channels\n",
    "        output_channels: Number of output channels\n",
    "    \n",
    "    Returns:\n",
    "        Fusion module\n",
    "    \"\"\"\n",
    "    if fusion_name == 'middle':\n",
    "        return MiddleFusionModule(\n",
    "            rgb_channels=rgb_channels,\n",
    "            depth_channels=depth_channels,\n",
    "            output_channels=output_channels\n",
    "        )\n",
    "    elif fusion_name == 'inception':\n",
    "        return InceptionFusion(\n",
    "            rgb_channels=rgb_channels,\n",
    "            depth_channels=depth_channels,\n",
    "            output_channels=output_channels\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown fusion module: {fusion_name}\")\n",
    "\n",
    "# Modify DualStreamCaloriePredictor to use different fusion modules\n",
    "class DualStreamCaloriePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Dual-stream CNN for calorie prediction using RGB and Depth images\n",
    "    Architecture: ResNet encoders + Fusion module + Regression head\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: str = 'resnet18',\n",
    "        fusion: str = 'middle',\n",
    "        fusion_channels: int = 512,\n",
    "        dropout_rate: float = 0.4,\n",
    "        pretrained: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # RGB and Depth encoders\n",
    "        self.rgb_encoder = ResNetEncoder(encoder, pretrained=pretrained, in_channels=3)\n",
    "        self.depth_encoder = ResNetEncoder(encoder, pretrained=pretrained, in_channels=1)\n",
    "        \n",
    "        # Create fusion module based on specified type\n",
    "        self.fusion = get_fusion_module(\n",
    "            fusion_name=fusion,\n",
    "            rgb_channels=self.rgb_encoder.out_channels,\n",
    "            depth_channels=self.depth_encoder.out_channels,\n",
    "            output_channels=fusion_channels\n",
    "        )\n",
    "        \n",
    "        # Regression head for calorie prediction\n",
    "        self.regression_head = RegressionHead(\n",
    "            in_channels=fusion_channels,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "    \n",
    "    def forward(self, rgb, depth):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rgb: RGB images (B, 3, H, W)\n",
    "            depth: Depth images (B, 1, H, W)\n",
    "        \n",
    "        Returns:\n",
    "            calorie_pred: Predicted calories (B, 1)\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        rgb_features = self.rgb_encoder(rgb)      # (B, 512, H/32, W/32)\n",
    "        depth_features = self.depth_encoder(depth)  # (B, 512, H/32, W/32)\n",
    "        \n",
    "        # Fuse features\n",
    "        fused_features = self.fusion(rgb_features, depth_features)  # (B, 512, H/32, W/32)\n",
    "        \n",
    "        # Predict calories\n",
    "        calorie_pred = self.regression_head(fused_features)  # (B, 1)\n",
    "        \n",
    "        return calorie_pred\n",
    "    \n",
    "    def get_num_parameters(self):\n",
    "        \"\"\"Get total number of trainable parameters\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "# Updated build_model function\n",
    "def build_model(encoder='resnet18', fusion='middle', regression_head='standard', \n",
    "                pretrained=False, dropout_rate=0.4, fusion_channels=512, **kwargs):\n",
    "    \"\"\"\n",
    "    Factory function to build models\n",
    "    \"\"\"\n",
    "    return DualStreamCaloriePredictor(\n",
    "        encoder=encoder,\n",
    "        fusion=fusion,\n",
    "        fusion_channels=fusion_channels,\n",
    "        dropout_rate=dropout_rate,\n",
    "        pretrained=pretrained\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b386b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Implementation\n",
    "class Nutrition5KDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for Nutrition5K with multi-modal inputs (RGB + Depth)\n",
    "    for calorie prediction only (no segmentation)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path: str,\n",
    "        data_root: str,\n",
    "        split: str = 'train',\n",
    "        augment: bool = True,\n",
    "        img_size: int = 224,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path: Path to the CSV file with dish IDs and calorie values\n",
    "            data_root: Root directory containing color/, depth_raw/ subdirectories\n",
    "            split: 'train' or 'val'\n",
    "            augment: Whether to apply data augmentation\n",
    "            img_size: Target image size for resizing\n",
    "            use_segmentation: Not used (kept for compatibility)\n",
    "        \"\"\"\n",
    "        self.data_root = data_root\n",
    "        self.split = split\n",
    "        self.augment = augment\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Load CSV\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        # Rename 'Value' column to 'calories' if it exists\n",
    "        if 'Value' in self.df.columns and 'calories' not in self.df.columns:\n",
    "            self.df = self.df.rename(columns={'Value': 'calories'})\n",
    "        # Make sure calories column exists\n",
    "        if 'calories' not in self.df.columns:\n",
    "            raise ValueError(\"CSV file must contain a 'calories' column or a 'Value' column that can be renamed\")\n",
    "        # Filter out high-calorie samples\n",
    "        self.df = self.df[self.df['calories'] < 3000].reset_index(drop=True)\n",
    "                \n",
    "        # Build paths\n",
    "        self.color_dir = os.path.join(data_root, 'color')\n",
    "        self.depth_raw_dir = os.path.join(data_root, 'depth_raw')\n",
    "        \n",
    "        # Validate dataset\n",
    "        self.valid_indices = self._validate_dataset()\n",
    "        print(f\"Loaded {len(self.valid_indices)} valid samples out of {len(self.df)}\")\n",
    "        \n",
    "        # Color normalization (ImageNet stats as baseline)\n",
    "        self.color_normalize = T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        \n",
    "    def _validate_dataset(self):\n",
    "        \"\"\"Pre-validate all samples and return valid indices\"\"\"\n",
    "        valid_indices = []\n",
    "        \n",
    "        for idx in range(len(self.df)):\n",
    "            dish_id = self.df.iloc[idx]['ID']\n",
    "            \n",
    "            rgb_path = os.path.join(self.color_dir, dish_id, 'rgb.png')\n",
    "            depth_path = os.path.join(self.depth_raw_dir, dish_id, 'depth_raw.png')\n",
    "            \n",
    "            # Check if files exist\n",
    "            if not os.path.exists(rgb_path):\n",
    "                continue\n",
    "            if not os.path.exists(depth_path):\n",
    "                continue\n",
    "            \n",
    "            # Try to load images to check for corruption\n",
    "            try:\n",
    "                with Image.open(rgb_path) as img:\n",
    "                    img.verify()\n",
    "                with Image.open(depth_path) as img:\n",
    "                    img.verify()\n",
    "                valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "        return valid_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def _load_image_safe(self, path: str, mode: str = 'RGB') -> Optional[Image.Image]:\n",
    "        \"\"\"Safely load an image with error handling\"\"\"\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                return img.convert(mode).copy()\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _apply_augmentation(self, rgb_img, depth_img):\n",
    "        \"\"\"Apply geometric augmentation only (no color changes)\"\"\"\n",
    "        if not self.augment:\n",
    "            return rgb_img, depth_img\n",
    "        \n",
    "        # Convert to tensors first\n",
    "        rgb_tensor = TF.to_tensor(rgb_img)\n",
    "        depth_tensor = TF.to_tensor(depth_img)\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            rgb_tensor = TF.hflip(rgb_tensor)\n",
    "            depth_tensor = TF.hflip(depth_tensor)\n",
    "        \n",
    "        # Random rotation (±15 degrees)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            rgb_tensor = TF.rotate(rgb_tensor, angle)\n",
    "            depth_tensor = TF.rotate(depth_tensor, angle)\n",
    "        \n",
    "        # Random resized crop\n",
    "        if random.random() > 0.4:  # 60% probability\n",
    "            i, j, h, w = T.RandomResizedCrop.get_params(\n",
    "                rgb_tensor, scale=(0.75, 1.0), ratio=(0.9, 1.1)\n",
    "            )\n",
    "            rgb_tensor = TF.resized_crop(rgb_tensor, i, j, h, w, (self.img_size, self.img_size))\n",
    "            depth_tensor = TF.resized_crop(depth_tensor, i, j, h, w, (self.img_size, self.img_size))\n",
    "        \n",
    "        # Convert back to PIL\n",
    "        rgb_img = TF.to_pil_image(rgb_tensor)\n",
    "        depth_img = TF.to_pil_image(depth_tensor)\n",
    "        \n",
    "        return rgb_img, depth_img\n",
    "    \n",
    "    def _resize_and_center_crop(self, img, target_size: int = 256):\n",
    "        \"\"\"\n",
    "        Resize and center crop image to target_size x target_size\n",
    "        Matches the preprocessing in the Nutrition5k paper\n",
    "        \n",
    "        Args:\n",
    "            img: PIL Image\n",
    "            target_size: Target size (default 256x256 as per paper)\n",
    "        \n",
    "        Returns:\n",
    "            Cropped PIL Image\n",
    "        \"\"\"\n",
    "        # Get original dimensions\n",
    "        width, height = img.size\n",
    "        \n",
    "        # Resize so the shorter side is target_size\n",
    "        if width < height:\n",
    "            new_width = target_size\n",
    "            new_height = int(target_size * height / width)\n",
    "        else:\n",
    "            new_height = target_size\n",
    "            new_width = int(target_size * width / height)\n",
    "        \n",
    "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        \n",
    "        # Center crop to target_size x target_size\n",
    "        left = (new_width - target_size) // 2\n",
    "        top = (new_height - target_size) // 2\n",
    "        right = left + target_size\n",
    "        bottom = top + target_size\n",
    "        \n",
    "        img = img.crop((left, top, right, bottom))\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a single sample\"\"\"\n",
    "        actual_idx = self.valid_indices[idx]\n",
    "        row = self.df.iloc[actual_idx]\n",
    "        \n",
    "        dish_id = row['ID']\n",
    "        calorie = float(row['calories'])\n",
    "        \n",
    "        # Load images\n",
    "        rgb_path = os.path.join(self.color_dir, dish_id, 'rgb.png')\n",
    "        depth_path = os.path.join(self.depth_raw_dir, dish_id, 'depth_raw.png')\n",
    "        \n",
    "        rgb_img = self._load_image_safe(rgb_path, 'RGB')\n",
    "        depth_img = self._load_image_safe(depth_path, 'L')  # Grayscale for depth\n",
    "        \n",
    "        if rgb_img is None or depth_img is None:\n",
    "            # Fallback: return a black image\n",
    "            rgb_img = Image.new('RGB', (self.img_size, self.img_size), (0, 0, 0))\n",
    "            depth_img = Image.new('L', (self.img_size, self.img_size), 0)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        rgb_img, depth_img = self._apply_augmentation(rgb_img, depth_img)\n",
    "        \n",
    "        # Resize and center crop to match paper preprocessing (256x256)\n",
    "        rgb_img = self._resize_and_center_crop(rgb_img, target_size=self.img_size)\n",
    "        depth_img = self._resize_and_center_crop(depth_img, target_size=self.img_size)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        rgb_tensor = TF.to_tensor(rgb_img)  # (3, H, W)\n",
    "        depth_tensor = TF.to_tensor(depth_img)  # (1, H, W)\n",
    "        \n",
    "        # Normalize RGB\n",
    "        rgb_tensor = self.color_normalize(rgb_tensor)\n",
    "        \n",
    "        # Normalize depth (0-1 range, assuming depth is already in reasonable range)\n",
    "        depth_tensor = depth_tensor / 255.0\n",
    "        \n",
    "        return {\n",
    "            'dish_id': dish_id,\n",
    "            'rgb': rgb_tensor,\n",
    "            'depth': depth_tensor,\n",
    "            'calorie': torch.tensor(calorie, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "\n",
    "def create_train_val_split(csv_path: str, val_ratio: float = 0.15, random_seed: int = 42):\n",
    "    \"\"\"\n",
    "    Create train/validation split CSV files\n",
    "    \"\"\"\n",
    "    # Read original CSV\n",
    "    df = pd.read_csv(csv_path)    \n",
    "    \n",
    "    # Shuffle with fixed seed\n",
    "    df_shuffled = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "    \n",
    "    # Split\n",
    "    val_size = int(len(df_shuffled) * val_ratio)\n",
    "    train_df = df_shuffled[val_size:]\n",
    "    val_df = df_shuffled[:val_size]\n",
    "    \n",
    "    # Save temporary CSV files\n",
    "    base_dir = os.path.dirname(csv_path)\n",
    "    train_csv = os.path.join(base_dir, 'train_split.csv')\n",
    "    val_csv = os.path.join(base_dir, 'val_split.csv')\n",
    "    \n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    val_df.to_csv(val_csv, index=False)\n",
    "    \n",
    "    return train_csv, val_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60078270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Utilities - Simplified for Calorie Prediction Only\n",
    "import math\n",
    "def get_warmup_cosine_scheduler(optimizer, warmup_steps, total_steps, min_lr_ratio=0.0):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        else:\n",
    "            progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "            # Scale from min_lr_ratio to 1.0 instead of 0.0 to 1.0\n",
    "            return min_lr_ratio + (1.0 - min_lr_ratio) * 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to stop training when validation loss stops improving\"\"\"\n",
    "    \n",
    "    def __init__(self, patience: int = 10, min_delta: float = 0.0, mode: str = 'min'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience: Number of epochs with no improvement after which training will be stopped\n",
    "            min_delta: Minimum change to qualify as an improvement\n",
    "            mode: 'min' or 'max' - whether lower or higher metric is better\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "    def __call__(self, score, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            improved = score < (self.best_score - self.min_delta)\n",
    "        else:\n",
    "            improved = score > (self.best_score + self.min_delta)\n",
    "        \n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                \n",
    "        return self.early_stop\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Training manager for calorie prediction\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        output_dir,\n",
    "        early_stopping_patience=15,\n",
    "        scheduler_step_on_batch=False\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.output_dir = output_dir\n",
    "        self.scheduler_step_on_batch = scheduler_step_on_batch\n",
    "        \n",
    "        # Early stopping\n",
    "        self.early_stopping = EarlyStopping(\n",
    "            patience=early_stopping_patience,\n",
    "            min_delta=0.1,\n",
    "            mode='min'\n",
    "        )\n",
    "        \n",
    "        # Tensorboard\n",
    "        self.writer = SummaryWriter(log_dir=os.path.join(output_dir, 'tensorboard'))\n",
    "        \n",
    "        # Tracking\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_metrics = {}\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            # Move to device\n",
    "            rgb = batch['rgb'].to(self.device)\n",
    "            depth = batch['depth'].to(self.device)\n",
    "            calories = batch['calorie'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            calorie_pred = self.model(rgb, depth)\n",
    "            \n",
    "            # Compute loss (MSE for calorie prediction)\n",
    "            loss = self.criterion(calorie_pred.squeeze(), calories)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Update learning rate (if step_on_batch)\n",
    "            if self.scheduler_step_on_batch and self.scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "                # Move to device\n",
    "                rgb = batch['rgb'].to(self.device)\n",
    "                depth = batch['depth'].to(self.device)\n",
    "                calories = batch['calorie'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                calorie_pred = self.model(rgb, depth)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = self.criterion(calorie_pred.squeeze(), calories)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Store predictions and targets for metrics\n",
    "                all_predictions.extend(calorie_pred.squeeze().cpu().numpy())\n",
    "                all_targets.extend(calories.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        predictions = np.array(all_predictions)\n",
    "        targets = np.array(all_targets)\n",
    "        \n",
    "        mae = np.mean(np.abs(predictions - targets))\n",
    "        \n",
    "        return avg_loss, mae\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        \"\"\"Full training loop\"\"\"\n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss = self.train_epoch()\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, mae = self.validate_epoch()\n",
    "            \n",
    "            # Update learning rate (if not step_on_batch)\n",
    "            if not self.scheduler_step_on_batch and self.scheduler:\n",
    "                self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Log metrics\n",
    "            self.writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "            self.writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "            self.writer.add_scalar('MAE', mae, epoch)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_metrics = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'val_loss': val_loss,\n",
    "                    'mae': mae,\n",
    "                }\n",
    "                \n",
    "                # Save model checkpoint\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'mae': mae,\n",
    "                }, os.path.join(self.output_dir, 'best_model.pth'))\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"MAE: {mae:.2f}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.early_stopping(val_loss, epoch):\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                print(f\"Best epoch: {self.early_stopping.best_epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        self.writer.close()\n",
    "        print(f\"\\nTraining completed!\")\n",
    "        print(f\"Best validation loss: {self.best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035e195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Data root: ../Nutrition5K/train\n",
      "  CSV path: ../Nutrition5K/nutrition5k_train.csv\n",
      "  Output directory: ../experiments\n",
      "  Batch size: 32\n",
      "  Number of epochs: 40\n",
      "  Image size: 256\n",
      "  Workers: 4\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Update these paths to match your setup\n",
    "DATA_ROOT = '../Nutrition5K/train'  # Path to training data directory\n",
    "CSV_PATH = '../Nutrition5K/nutrition5k_train.csv'  # Path to training CSV\n",
    "OUTPUT_DIR = '../experiments'  # Directory to save experiment results\n",
    "\n",
    "# Global training hyperparameters (learning rate and weight decay set per experiment)\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "VAL_RATIO = 0.15\n",
    "IMG_SIZE = 256\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data root: {DATA_ROOT}\")\n",
    "print(f\"  CSV path: {CSV_PATH}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Number of epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Image size: {IMG_SIZE}\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f256ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1.1 Dataset Loading and Exploration\n",
    "\n",
    "First, let's load the dataset and examine some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947c256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation split...\n",
      "Train CSV: ../Nutrition5K/train_split.csv\n",
      "Validation CSV: ../Nutrition5K/val_split.csv\n",
      "Loaded 2804 valid samples out of 2805\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Training samples: 2804\n",
      "RGB shape: torch.Size([3, 256, 256])\n",
      "Depth shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Create train/validation split\n",
    "print(\"Creating train/validation split...\")\n",
    "train_csv, val_csv = create_train_val_split(\n",
    "    CSV_PATH,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Train CSV: {train_csv}\")\n",
    "print(f\"Validation CSV: {val_csv}\")\n",
    "\n",
    "# Load a sample to check data\n",
    "sample_dataset = Nutrition5KDataset(\n",
    "    csv_path=train_csv,\n",
    "    data_root=DATA_ROOT,\n",
    "    split='train',\n",
    "    augment=False,  # No augmentation for checking\n",
    "    img_size=IMG_SIZE,\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Training samples: {len(sample_dataset)}\")\n",
    "print(f\"RGB shape: {sample_dataset[0]['rgb'].shape}\")\n",
    "print(f\"Depth shape: {sample_dataset[0]['depth'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6f3b0",
   "metadata": {},
   "source": [
    "# 2. Experiments\n",
    "\n",
    "We'll conduct experiments to compare different encoder architectures with and without data augmentation.\n",
    "\n",
    "**Architecture**: Dual-stream CNN with middle fusion\n",
    "- **RGB encoder**: ResNet (18 or 34)\n",
    "- **Depth encoder**: ResNet (18 or 34) \n",
    "- **Fusion**: Standard middle fusion (concatenate + 1x1 conv)\n",
    "- **Regression head**: Standard (no segmentation head)\n",
    "\n",
    "**Experiments**:\n",
    "1. ResNet-18 without augmentation (baseline)\n",
    "2. ResNet-18 with geometric augmentation\n",
    "3. ResNet-34 without augmentation\n",
    "4. ResNet-34 with geometric augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a0f8f",
   "metadata": {},
   "source": [
    "## 2.1 Encoder Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced54ebe",
   "metadata": {},
   "source": [
    "### Resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77258dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_RATE = 0.3\n",
    "FUSION_CHANNELS = 512\n",
    "WEIGHT_DECAY = 1e-6\n",
    "\n",
    "### LR HYPERPARAMETER\n",
    "LEARNING_RATE = 8e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "EARLY_STOPPING_PATIENCE = 7\n",
    "WARMUP_RATIO = 0.1\n",
    "MIN_LR_RATIO = 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c14a3",
   "metadata": {},
   "source": [
    "#### No Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40330f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-18 + Middle Fusion (No Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 22,872,577\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=133763.1250]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99588.1862\n",
      "Val Loss: 107512.8083\n",
      "MAE: 240.83\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.20it/s, Loss=141186.5469]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 93442.4327\n",
      "Val Loss: 103962.4995\n",
      "MAE: 237.11\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=99093.0859] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 86276.3308\n",
      "Val Loss: 98197.5698\n",
      "MAE: 230.58\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.23it/s, Loss=111384.7266]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 84149.6715\n",
      "Val Loss: 88746.1426\n",
      "MAE: 219.59\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.23it/s, Loss=28057.3594] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 75295.6496\n",
      "Val Loss: 92595.2842\n",
      "MAE: 223.49\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.35it/s, Loss=46992.6055] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 61697.3167\n",
      "Val Loss: 91651.7266\n",
      "MAE: 224.38\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=60788.6055]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 53400.3644\n",
      "Val Loss: 62524.8992\n",
      "MAE: 185.24\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.27it/s, Loss=34053.6484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 45799.7142\n",
      "Val Loss: 24355.4155\n",
      "MAE: 108.24\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.20it/s, Loss=27366.5625]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 32245.2867\n",
      "Val Loss: 22714.7631\n",
      "MAE: 108.30\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=41695.0000]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 25916.9160\n",
      "Val Loss: 29127.6378\n",
      "MAE: 119.48\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.16it/s, Loss=46365.9688]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 23139.5869\n",
      "Val Loss: 22053.3058\n",
      "MAE: 102.53\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=11850.5859]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 21686.7587\n",
      "Val Loss: 23139.7461\n",
      "MAE: 105.16\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=12574.7012]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 20232.6971\n",
      "Val Loss: 24064.0271\n",
      "MAE: 109.80\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.25it/s, Loss=20526.3574]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19758.3131\n",
      "Val Loss: 18914.3069\n",
      "MAE: 93.01\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=6123.2905] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16014.0262\n",
      "Val Loss: 14381.4912\n",
      "MAE: 84.00\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.10it/s, Loss=9073.8311] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11504.8771\n",
      "Val Loss: 12995.8126\n",
      "MAE: 78.00\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.17it/s, Loss=7422.2266] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11147.3752\n",
      "Val Loss: 21229.2983\n",
      "MAE: 93.32\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=5081.7520] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8305.5386\n",
      "Val Loss: 12627.0216\n",
      "MAE: 73.45\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.26it/s, Loss=6787.8247] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7987.3262\n",
      "Val Loss: 16497.1763\n",
      "MAE: 83.85\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.18it/s, Loss=6696.3540] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6417.7676\n",
      "Val Loss: 11754.7650\n",
      "MAE: 71.26\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.20it/s, Loss=10333.9219]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5866.7414\n",
      "Val Loss: 15421.7828\n",
      "MAE: 81.27\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.24it/s, Loss=5702.7783] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4544.9265\n",
      "Val Loss: 11149.9972\n",
      "MAE: 69.17\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=5078.2197] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4773.5788\n",
      "Val Loss: 11223.6857\n",
      "MAE: 69.60\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.29it/s, Loss=8156.5493] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3865.6909\n",
      "Val Loss: 11224.7352\n",
      "MAE: 68.30\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.30it/s, Loss=806.0511]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3399.2716\n",
      "Val Loss: 10764.9377\n",
      "MAE: 68.89\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=1323.5074] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2947.6614\n",
      "Val Loss: 10486.2951\n",
      "MAE: 66.10\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=1762.6411]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2471.1973\n",
      "Val Loss: 10716.0076\n",
      "MAE: 65.75\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.38it/s, Loss=2050.8726] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3069.4038\n",
      "Val Loss: 10138.0582\n",
      "MAE: 64.78\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.27it/s, Loss=2013.9670] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2423.1852\n",
      "Val Loss: 10326.1784\n",
      "MAE: 65.28\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.33it/s, Loss=4890.8232] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2742.4033\n",
      "Val Loss: 10311.3268\n",
      "MAE: 64.67\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.15it/s, Loss=863.5477]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2687.8933\n",
      "Val Loss: 9637.1174\n",
      "MAE: 64.59\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.24it/s, Loss=1831.1860] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2347.0324\n",
      "Val Loss: 10456.0297\n",
      "MAE: 65.15\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.24it/s, Loss=978.8034]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2447.3693\n",
      "Val Loss: 9988.2896\n",
      "MAE: 66.15\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=1020.9728] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2858.6214\n",
      "Val Loss: 10273.5074\n",
      "MAE: 65.81\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.15it/s, Loss=1495.0374] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2467.6893\n",
      "Val Loss: 9509.0767\n",
      "MAE: 63.78\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.28it/s, Loss=628.3477]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2286.3173\n",
      "Val Loss: 10011.1221\n",
      "MAE: 64.81\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.18it/s, Loss=1538.4891] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2130.9190\n",
      "Val Loss: 9982.3984\n",
      "MAE: 64.79\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.12it/s, Loss=2675.0352] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2215.4360\n",
      "Val Loss: 10430.9554\n",
      "MAE: 64.50\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.32it/s, Loss=4496.9961] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2082.9309\n",
      "Val Loss: 9938.9886\n",
      "MAE: 63.33\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.33it/s, Loss=695.4222]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2364.3041\n",
      "Val Loss: 9860.9779\n",
      "MAE: 63.48\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 9509.0767\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp1_resnet18_no_aug_20251023_115441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-18 without Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-18 baseline (no augmentation)\n",
    "def train_resnet18_no_aug():\n",
    "    \"\"\"Train ResNet-18 with standard middle fusion, no data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-18 + Middle Fusion (No Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (no augmentation)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,  # No augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-18 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet18',\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "        use_segmentation=False  # Calorie prediction only\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "        \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp1_resnet18_no_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet18_no_aug_results = train_resnet18_no_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706592e",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f015d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-18 + Middle Fusion (With Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 22,872,577\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.53it/s, Loss=85079.6875] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99051.7583\n",
      "Val Loss: 107375.8743\n",
      "MAE: 240.59\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.73it/s, Loss=90859.1875] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 92092.3763\n",
      "Val Loss: 89712.8545\n",
      "MAE: 217.80\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=106267.1406]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 80478.5505\n",
      "Val Loss: 87209.2805\n",
      "MAE: 217.54\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.56it/s, Loss=28713.6836] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 67525.8587\n",
      "Val Loss: 62231.3778\n",
      "MAE: 183.26\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=46846.4766] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 51258.9550\n",
      "Val Loss: 52674.6289\n",
      "MAE: 164.88\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  5.81it/s, Loss=32966.6562]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 39434.6136\n",
      "Val Loss: 41577.8690\n",
      "MAE: 143.61\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=15293.2910]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 35792.9151\n",
      "Val Loss: 34405.6172\n",
      "MAE: 129.27\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.69it/s, Loss=13171.5469]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 34169.2190\n",
      "Val Loss: 34256.6227\n",
      "MAE: 128.45\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.71it/s, Loss=62203.7422]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 32442.9426\n",
      "Val Loss: 25855.3765\n",
      "MAE: 109.53\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.73it/s, Loss=10341.1270]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 30892.9986\n",
      "Val Loss: 26920.1313\n",
      "MAE: 111.00\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.69it/s, Loss=9082.0469] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 23164.5244\n",
      "Val Loss: 22798.4934\n",
      "MAE: 109.95\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.77it/s, Loss=18253.8965]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 20198.7868\n",
      "Val Loss: 19570.6440\n",
      "MAE: 93.34\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  5.85it/s, Loss=23779.0977]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19983.7109\n",
      "Val Loss: 21073.9814\n",
      "MAE: 99.18\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=21315.0508]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16180.7460\n",
      "Val Loss: 16609.2760\n",
      "MAE: 88.62\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.77it/s, Loss=12850.5508]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14903.0190\n",
      "Val Loss: 17341.5691\n",
      "MAE: 89.21\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=12160.0850]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15465.6358\n",
      "Val Loss: 14978.9188\n",
      "MAE: 83.28\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.71it/s, Loss=5302.0918] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13682.1568\n",
      "Val Loss: 15086.6279\n",
      "MAE: 87.54\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=7335.4014] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12730.4589\n",
      "Val Loss: 14327.3149\n",
      "MAE: 80.47\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.70it/s, Loss=6568.0122] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14864.4008\n",
      "Val Loss: 14101.0120\n",
      "MAE: 81.60\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=23456.0117]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13990.6148\n",
      "Val Loss: 14978.9472\n",
      "MAE: 87.05\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  5.85it/s, Loss=3628.8484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11979.8724\n",
      "Val Loss: 14753.5390\n",
      "MAE: 80.00\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=16214.7764]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11947.5883\n",
      "Val Loss: 28577.6626\n",
      "MAE: 128.53\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.72it/s, Loss=9879.6221] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10679.9352\n",
      "Val Loss: 10907.9683\n",
      "MAE: 73.49\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.70it/s, Loss=15936.9922]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10730.9533\n",
      "Val Loss: 12514.4612\n",
      "MAE: 75.19\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.73it/s, Loss=12725.4805]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13483.8592\n",
      "Val Loss: 22171.8800\n",
      "MAE: 97.76\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.77it/s, Loss=10055.9473]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11926.3028\n",
      "Val Loss: 11966.0764\n",
      "MAE: 78.20\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.70it/s, Loss=12188.3887]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12080.6302\n",
      "Val Loss: 19402.6888\n",
      "MAE: 93.71\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=8683.4180] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12543.2637\n",
      "Val Loss: 14072.2663\n",
      "MAE: 81.51\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.75it/s, Loss=14817.7559]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11841.4046\n",
      "Val Loss: 11159.2817\n",
      "MAE: 72.23\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.63it/s, Loss=8485.0615] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10617.0792\n",
      "Val Loss: 11197.8942\n",
      "MAE: 70.36\n",
      "Early stopping triggered after 30 epochs\n",
      "Best epoch: 23\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 10907.9683\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp2_resnet18_with_aug_20251023_120817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-18 with Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-18 with geometric augmentation\n",
    "def train_resnet18_with_aug():\n",
    "    \"\"\"Train ResNet-18 with standard middle fusion and geometric data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-18 + Middle Fusion (With Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (with augmentation for training)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=True,  # Enable geometric augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-18 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet18',\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "        use_segmentation=False  # Calorie prediction only\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp2_resnet18_with_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet18_with_aug_results = train_resnet18_with_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3a407",
   "metadata": {},
   "source": [
    "### Resnet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afc023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_RATE = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccdf09",
   "metadata": {},
   "source": [
    "#### No Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ab59db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-34 + Middle Fusion (No Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 43,088,897\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.14it/s, Loss=100307.0469]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 98698.4380\n",
      "Val Loss: 107480.8511\n",
      "MAE: 240.78\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.03it/s, Loss=115505.5078]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 93298.1988\n",
      "Val Loss: 94860.5649\n",
      "MAE: 225.05\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.13it/s, Loss=97543.1484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 78814.7641\n",
      "Val Loss: 75482.5867\n",
      "MAE: 198.21\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.02it/s, Loss=46035.8828] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 63182.2442\n",
      "Val Loss: 67355.9116\n",
      "MAE: 188.14\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.10it/s, Loss=34015.9844]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 48316.3558\n",
      "Val Loss: 44795.5026\n",
      "MAE: 151.35\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.96it/s, Loss=27088.8945]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 39746.4579\n",
      "Val Loss: 101420.4907\n",
      "MAE: 230.74\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=32450.6348]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 29236.0380\n",
      "Val Loss: 26153.1317\n",
      "MAE: 114.16\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.16it/s, Loss=27458.8535]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 22065.8771\n",
      "Val Loss: 26824.6976\n",
      "MAE: 112.60\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.15it/s, Loss=38509.7695]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 18690.6027\n",
      "Val Loss: 18364.3469\n",
      "MAE: 91.84\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.96it/s, Loss=8189.1870] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16459.1131\n",
      "Val Loss: 23371.7727\n",
      "MAE: 103.03\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.94it/s, Loss=10984.0146]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14646.5586\n",
      "Val Loss: 14422.5637\n",
      "MAE: 82.67\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.05it/s, Loss=9203.7559] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13891.2966\n",
      "Val Loss: 25593.7811\n",
      "MAE: 113.19\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=13003.4951]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14939.9415\n",
      "Val Loss: 14794.3045\n",
      "MAE: 82.83\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.89it/s, Loss=10545.8398]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12406.2784\n",
      "Val Loss: 19018.4198\n",
      "MAE: 92.15\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.94it/s, Loss=8548.8857] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13727.4712\n",
      "Val Loss: 14259.7208\n",
      "MAE: 84.05\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.02it/s, Loss=36374.4219]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11469.9134\n",
      "Val Loss: 20453.0985\n",
      "MAE: 104.23\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.99it/s, Loss=16884.9199]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11314.3521\n",
      "Val Loss: 12779.0828\n",
      "MAE: 76.06\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=25691.1680]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12437.8630\n",
      "Val Loss: 13685.8074\n",
      "MAE: 88.04\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.91it/s, Loss=12364.6943]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11531.3536\n",
      "Val Loss: 16079.4240\n",
      "MAE: 86.28\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=6178.0864] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9448.1288\n",
      "Val Loss: 11009.8374\n",
      "MAE: 73.60\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.14it/s, Loss=20019.0801]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9207.7607\n",
      "Val Loss: 11962.1297\n",
      "MAE: 73.78\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.89it/s, Loss=17639.1445]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9813.5774\n",
      "Val Loss: 12778.6039\n",
      "MAE: 85.70\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=14909.9268]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10323.5442\n",
      "Val Loss: 13187.3307\n",
      "MAE: 78.38\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=9893.2422] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9807.8190\n",
      "Val Loss: 24089.0463\n",
      "MAE: 105.49\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.13it/s, Loss=4728.5957] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8599.6537\n",
      "Val Loss: 11012.7349\n",
      "MAE: 72.33\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.06it/s, Loss=7365.0635] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7456.4367\n",
      "Val Loss: 10319.1408\n",
      "MAE: 73.22\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.98it/s, Loss=6135.0625] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6794.7576\n",
      "Val Loss: 10980.3264\n",
      "MAE: 71.21\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.23it/s, Loss=9630.8418] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6846.5313\n",
      "Val Loss: 10542.8580\n",
      "MAE: 70.73\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=8346.2324] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6120.3744\n",
      "Val Loss: 10586.5872\n",
      "MAE: 71.17\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=3144.8523] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5767.9688\n",
      "Val Loss: 10592.2169\n",
      "MAE: 70.01\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.05it/s, Loss=3549.7461] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5589.9075\n",
      "Val Loss: 9911.6910\n",
      "MAE: 69.30\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.00it/s, Loss=6178.6987] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4955.1105\n",
      "Val Loss: 9756.2419\n",
      "MAE: 66.65\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.00it/s, Loss=5042.2383] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5144.2286\n",
      "Val Loss: 9133.4005\n",
      "MAE: 66.62\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=2124.5842] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5153.8232\n",
      "Val Loss: 10263.6432\n",
      "MAE: 67.77\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.07it/s, Loss=3494.1531] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4622.9021\n",
      "Val Loss: 9445.4597\n",
      "MAE: 67.23\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.03it/s, Loss=6312.3218] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4337.2332\n",
      "Val Loss: 9587.0288\n",
      "MAE: 66.16\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.10it/s, Loss=3321.8247] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4557.4898\n",
      "Val Loss: 9253.1733\n",
      "MAE: 66.74\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.95it/s, Loss=5787.7773] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4288.3274\n",
      "Val Loss: 9847.6848\n",
      "MAE: 66.14\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.13it/s, Loss=16884.8047]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4522.8226\n",
      "Val Loss: 9699.7839\n",
      "MAE: 65.64\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.14it/s, Loss=3016.7654] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4215.9819\n",
      "Val Loss: 9186.5228\n",
      "MAE: 66.61\n",
      "Early stopping triggered after 40 epochs\n",
      "Best epoch: 33\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 9133.4005\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp3_resnet34_no_aug_20251023_122720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-34 without Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-34 baseline (no augmentation)\n",
    "def train_resnet34_no_aug():\n",
    "    \"\"\"Train ResNet-34 with standard middle fusion, no data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-34 + Middle Fusion (No Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (no augmentation)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,  # No augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-34 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet34',  # ResNet-34 instead of ResNet-18\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp3_resnet34_no_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet34_no_aug_results = train_resnet34_no_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eac883",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e5d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-34 + Middle Fusion (With Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 43,088,897\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=65703.4531] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99124.6188\n",
      "Val Loss: 107322.5024\n",
      "MAE: 240.47\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.47it/s, Loss=81227.3125] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 92163.1452\n",
      "Val Loss: 70563.1094\n",
      "MAE: 189.04\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=65766.6562] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 79277.6088\n",
      "Val Loss: 62262.4773\n",
      "MAE: 179.65\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=42776.0312] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 64958.0558\n",
      "Val Loss: 75921.1836\n",
      "MAE: 202.48\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.68it/s, Loss=52520.8555] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 47652.4703\n",
      "Val Loss: 27046.1724\n",
      "MAE: 112.44\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=37497.9062]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 35633.5909\n",
      "Val Loss: 44948.1774\n",
      "MAE: 152.45\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=15921.7324]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 28943.8791\n",
      "Val Loss: 25409.8503\n",
      "MAE: 109.18\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=44251.2031]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 23026.0490\n",
      "Val Loss: 20512.8347\n",
      "MAE: 103.17\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.59it/s, Loss=24961.2812]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19919.7775\n",
      "Val Loss: 17823.4903\n",
      "MAE: 93.93\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.53it/s, Loss=10958.9531]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 18776.1287\n",
      "Val Loss: 19065.1475\n",
      "MAE: 94.96\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=11959.9941]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 17042.8688\n",
      "Val Loss: 28164.3819\n",
      "MAE: 113.20\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.59it/s, Loss=12711.7285]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15348.4762\n",
      "Val Loss: 15656.5202\n",
      "MAE: 82.92\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.42it/s, Loss=21801.0664]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14084.3811\n",
      "Val Loss: 15010.1869\n",
      "MAE: 83.01\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=8133.9629] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14246.3937\n",
      "Val Loss: 14875.6891\n",
      "MAE: 87.88\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=8740.6484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13632.3354\n",
      "Val Loss: 14886.5533\n",
      "MAE: 79.79\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.44it/s, Loss=11381.8145]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13038.1456\n",
      "Val Loss: 13794.5543\n",
      "MAE: 82.48\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.37it/s, Loss=17942.4883]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15187.8177\n",
      "Val Loss: 32055.9642\n",
      "MAE: 123.19\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=36162.6016]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14826.7194\n",
      "Val Loss: 17379.2682\n",
      "MAE: 93.02\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.43it/s, Loss=11861.8438]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13144.0944\n",
      "Val Loss: 14248.9747\n",
      "MAE: 84.41\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=9118.6777] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13952.7637\n",
      "Val Loss: 13507.6129\n",
      "MAE: 77.29\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=21224.3145]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13972.1001\n",
      "Val Loss: 32404.5224\n",
      "MAE: 117.05\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=8671.5127] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13516.1525\n",
      "Val Loss: 30858.1169\n",
      "MAE: 114.47\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=9823.3320] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12994.4469\n",
      "Val Loss: 20585.9318\n",
      "MAE: 107.96\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.43it/s, Loss=10844.4121]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11785.2529\n",
      "Val Loss: 23457.3118\n",
      "MAE: 116.36\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.52it/s, Loss=11628.8770]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12374.6989\n",
      "Val Loss: 13104.0104\n",
      "MAE: 81.99\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=13174.1152]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13864.0507\n",
      "Val Loss: 13701.1168\n",
      "MAE: 77.02\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=16515.8867]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12282.9718\n",
      "Val Loss: 16767.4535\n",
      "MAE: 85.84\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.62it/s, Loss=13672.0781]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11222.3651\n",
      "Val Loss: 11760.0813\n",
      "MAE: 74.16\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.51it/s, Loss=11469.0137]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11469.0313\n",
      "Val Loss: 12901.5543\n",
      "MAE: 77.10\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.63it/s, Loss=8778.0020] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13145.7783\n",
      "Val Loss: 16580.6470\n",
      "MAE: 95.21\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=9461.3086] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11599.1675\n",
      "Val Loss: 12117.7284\n",
      "MAE: 76.53\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=16782.4375]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12341.5115\n",
      "Val Loss: 19674.3840\n",
      "MAE: 104.23\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=22410.3828]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11471.6048\n",
      "Val Loss: 22065.4567\n",
      "MAE: 112.77\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=11226.2793]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10118.9804\n",
      "Val Loss: 12113.4151\n",
      "MAE: 74.36\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=18005.9375]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10894.2290\n",
      "Val Loss: 30447.4351\n",
      "MAE: 115.17\n",
      "Early stopping triggered after 35 epochs\n",
      "Best epoch: 28\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 11760.0813\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp4_resnet34_with_aug_20251023_123711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-34 with Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-34 with geometric augmentation\n",
    "def train_resnet34_with_aug():\n",
    "    \"\"\"Train ResNet-34 with standard middle fusion and geometric data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-34 + Middle Fusion (With Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (with augmentation for training)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=True,  # Enable geometric augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-34 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet34',  # ResNet-34 instead of ResNet-18\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp4_resnet34_with_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet34_with_aug_results = train_resnet34_with_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c355293",
   "metadata": {},
   "source": [
    "### Results Summary and Analysis\n",
    "\n",
    "Compare the results from different encoder architectures and the effect of data augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6a23373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENCODER EXPERIMENT RESULTS COMPARISON\n",
      "================================================================================\n",
      "Experiment                Val Loss   MAE        Best Epoch  \n",
      "--------------------------------------------------------------------------------\n",
      "ResNet-18 (No Aug)        9509.0767  63.78      35          \n",
      "ResNet-18 (With Aug)      10907.9683 73.49      23          \n",
      "ResNet-34 (No Aug)        9133.4005  66.62      33          \n",
      "ResNet-34 (With Aug)      11760.0813 74.16      28          \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare results from all encoder experiments\n",
    "def compare_encoder_results():\n",
    "    \"\"\"Compare results from all encoder experiments\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ENCODER EXPERIMENT RESULTS COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Collect results (these variables should exist after running experiments)\n",
    "    results = [\n",
    "        (\"ResNet-18 (No Aug)\", resnet18_no_aug_results),\n",
    "        (\"ResNet-18 (With Aug)\", resnet18_with_aug_results),\n",
    "        (\"ResNet-34 (No Aug)\", resnet34_no_aug_results),\n",
    "        (\"ResNet-34 (With Aug)\", resnet34_with_aug_results)\n",
    "    ]\n",
    "    \n",
    "    # Display results in a table format\n",
    "    print(f\"{'Experiment':<25} {'Val Loss':<10} {'MAE':<10} {'Best Epoch':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for name, metrics in results:\n",
    "        val_loss = metrics['val_loss']\n",
    "        mae = metrics['mae']\n",
    "        epoch = metrics['epoch']\n",
    "        \n",
    "        print(f\"{name:<25} {val_loss:<10.4f} {mae:<10.2f} {epoch:<12}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "# Run the comparison\n",
    "compare_encoder_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6f8d2",
   "metadata": {},
   "source": [
    "## 2.2 Inception Experiment\n",
    "\n",
    "In this experiment, we'll use the ResNet-18 encoder with Inception fusion module instead of the standard middle fusion. We'll keep the same settings (no augmentation) as in our best performing experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e9829",
   "metadata": {},
   "source": [
    "### InceptionV3 - Middle Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93511e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: Nutrition5k InceptionV3 + Middle Fusion\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 53,143,873\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0003\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.64it/s, Loss=128571.7500]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99180.2905\n",
      "Val Loss: 107414.4023\n",
      "MAE: 240.64\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=17922.5977] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 46328.7172\n",
      "Val Loss: 19609.8160\n",
      "MAE: 98.70\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=17257.0234]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 17565.5851\n",
      "Val Loss: 18237.3756\n",
      "MAE: 101.44\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.67it/s, Loss=14054.9883]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16342.3404\n",
      "Val Loss: 18777.5775\n",
      "MAE: 92.01\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=10758.4248]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16610.0277\n",
      "Val Loss: 15346.2289\n",
      "MAE: 88.26\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=7126.8857] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13270.2321\n",
      "Val Loss: 13577.7117\n",
      "MAE: 81.94\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=16134.1768]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14738.7614\n",
      "Val Loss: 25312.3941\n",
      "MAE: 117.74\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=10888.4346]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15134.3133\n",
      "Val Loss: 38001.6630\n",
      "MAE: 129.31\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=19213.4512]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14339.6015\n",
      "Val Loss: 13877.6940\n",
      "MAE: 84.41\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=25606.4414]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13312.2757\n",
      "Val Loss: 18398.2153\n",
      "MAE: 89.72\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=9016.8955] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12421.9098\n",
      "Val Loss: 13448.8066\n",
      "MAE: 79.60\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=9204.4150] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12134.3546\n",
      "Val Loss: 12958.2929\n",
      "MAE: 82.99\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.69it/s, Loss=11199.6592]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11873.8549\n",
      "Val Loss: 15488.9226\n",
      "MAE: 87.67\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=23062.0352]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9654.9122\n",
      "Val Loss: 9652.0177\n",
      "MAE: 71.04\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=8756.7197] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8432.4198\n",
      "Val Loss: 10057.4061\n",
      "MAE: 68.72\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=6628.3955] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8288.8200\n",
      "Val Loss: 9020.5332\n",
      "MAE: 68.89\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:54<00:00,  1.60it/s, Loss=5914.1670] \n",
      "Validation: 100%|██████████| 16/16 [00:08<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7726.7897\n",
      "Val Loss: 9448.8025\n",
      "MAE: 68.31\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:56<00:00,  1.53it/s, Loss=11372.3418]\n",
      "Validation: 100%|██████████| 16/16 [00:08<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7632.8732\n",
      "Val Loss: 9006.3277\n",
      "MAE: 66.99\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.65it/s, Loss=3588.7578] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8112.8181\n",
      "Val Loss: 8675.7210\n",
      "MAE: 67.31\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.65it/s, Loss=4178.5337] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7875.6926\n",
      "Val Loss: 8580.3945\n",
      "MAE: 65.25\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=9267.5488] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8341.5432\n",
      "Val Loss: 14076.6368\n",
      "MAE: 76.34\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=8067.8755] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8919.7032\n",
      "Val Loss: 12730.7898\n",
      "MAE: 79.53\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=8183.2783] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9857.7080\n",
      "Val Loss: 14884.1973\n",
      "MAE: 82.11\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.67it/s, Loss=1323.7805] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8445.4311\n",
      "Val Loss: 9205.0922\n",
      "MAE: 66.60\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=6407.5298] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7198.7125\n",
      "Val Loss: 8406.5140\n",
      "MAE: 63.74\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=4699.6421] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7130.2759\n",
      "Val Loss: 8645.6742\n",
      "MAE: 64.49\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:53<00:00,  1.64it/s, Loss=3984.9800] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6688.6678\n",
      "Val Loss: 9509.4421\n",
      "MAE: 66.30\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=3447.1079] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6170.6188\n",
      "Val Loss: 8299.3873\n",
      "MAE: 63.26\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=12864.9551]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7237.8025\n",
      "Val Loss: 8874.0362\n",
      "MAE: 64.52\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=7572.9497] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6965.5601\n",
      "Val Loss: 8535.5627\n",
      "MAE: 62.84\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=4612.9033] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5913.7369\n",
      "Val Loss: 9276.4340\n",
      "MAE: 65.43\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.67it/s, Loss=2796.8223] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5462.4462\n",
      "Val Loss: 7366.6407\n",
      "MAE: 58.27\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=11851.7471]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7867.3449\n",
      "Val Loss: 9761.6551\n",
      "MAE: 68.12\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.65it/s, Loss=7643.1602] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6514.1321\n",
      "Val Loss: 8613.1119\n",
      "MAE: 61.72\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=7990.2661] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6318.7211\n",
      "Val Loss: 9577.9856\n",
      "MAE: 64.07\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.68it/s, Loss=4835.8301] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5574.1088\n",
      "Val Loss: 8083.3627\n",
      "MAE: 61.45\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=10193.6895]\n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6303.8335\n",
      "Val Loss: 9405.3488\n",
      "MAE: 68.76\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=6055.8232] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5595.0879\n",
      "Val Loss: 7646.4819\n",
      "MAE: 57.92\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:51<00:00,  1.69it/s, Loss=5701.7896] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7058.9306\n",
      "Val Loss: 9062.2735\n",
      "MAE: 63.46\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:52<00:00,  1.66it/s, Loss=6776.0557] \n",
      "Validation: 100%|██████████| 16/16 [00:07<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5861.4637\n",
      "Val Loss: 8159.9315\n",
      "MAE: 59.92\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 7366.6407\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/nutrition5k_experiments/inceptionv3_middle_fusion_20251024_003206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new cell with this code to run the Nutrition5k InceptionV3 experiments\n",
    "\n",
    "# Import the necessary modules\n",
    "import sys\n",
    "sys.path.append('/data/projects/punim0478/setiawand/Computer-Vision-COMP90086/src')\n",
    "\n",
    "from nutrition5k_inceptionv3_model import build_nutrition5k_model\n",
    "\n",
    "# Configure experiment settings\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "DROPOUT_RATE = 0.4\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "WARMUP_RATIO = 0.1\n",
    "MIN_LR_RATIO = 0.05\n",
    "FUSION_CHANNELS = 2048  # InceptionV3 output channels\n",
    "\n",
    "def train_nutrition5k_model(fusion_type='middle'):\n",
    "    \"\"\"Train the Nutrition5k model with InceptionV3 and specified fusion type\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TRAINING: Nutrition5k InceptionV3 + {fusion_type.capitalize()} Fusion\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model with specified fusion type\n",
    "    model = build_nutrition5k_model(\n",
    "        fusion=fusion_type,\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "    \n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"inceptionv3_{fusion_type}_fusion_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, 'nutrition5k_experiments', exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Save experiment configuration\n",
    "    config = {\n",
    "        'fusion': fusion_type,\n",
    "        'pretrained': False,\n",
    "        'dropout_rate': DROPOUT_RATE,\n",
    "        'fusion_channels': FUSION_CHANNELS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'img_size': IMG_SIZE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(exp_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run an experiment with middle fusion\n",
    "middle_fusion_results = train_nutrition5k_model(fusion_type='middle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b88a84",
   "metadata": {},
   "source": [
    "### InceptionV3 - Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d1f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: Nutrition5k InceptionV3 + Early Fusion\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 22,966,465\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0003\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:19<00:00,  4.42it/s, Loss=133707.4688]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99300.4746\n",
      "Val Loss: 107394.6609\n",
      "MAE: 240.60\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:19<00:00,  4.56it/s, Loss=15556.5234] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 48631.2526\n",
      "Val Loss: 20554.5145\n",
      "MAE: 103.99\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.38it/s, Loss=26694.4277]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19130.2747\n",
      "Val Loss: 20629.0604\n",
      "MAE: 103.02\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=12812.8926]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16128.2771\n",
      "Val Loss: 18271.5989\n",
      "MAE: 98.67\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=28091.8711]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 17400.8946\n",
      "Val Loss: 22178.2593\n",
      "MAE: 107.40\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.65it/s, Loss=12066.3076]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16233.5468\n",
      "Val Loss: 16204.2562\n",
      "MAE: 91.46\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=13115.3047]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14097.9216\n",
      "Val Loss: 15439.4271\n",
      "MAE: 87.74\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=5877.3989] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13979.7379\n",
      "Val Loss: 15428.1564\n",
      "MAE: 84.98\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.68it/s, Loss=10579.7461]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13369.9464\n",
      "Val Loss: 14027.8607\n",
      "MAE: 83.65\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=5037.1177] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16204.9514\n",
      "Val Loss: 25229.5847\n",
      "MAE: 102.97\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=20603.3398]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 17118.4275\n",
      "Val Loss: 28385.8293\n",
      "MAE: 111.16\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.77it/s, Loss=14363.6553]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14747.8151\n",
      "Val Loss: 15166.7603\n",
      "MAE: 86.35\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.67it/s, Loss=15481.0938]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13513.0611\n",
      "Val Loss: 17695.2841\n",
      "MAE: 88.76\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=22692.3008]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14401.6315\n",
      "Val Loss: 15636.0155\n",
      "MAE: 89.89\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=10330.4033]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11960.9114\n",
      "Val Loss: 12410.3653\n",
      "MAE: 79.94\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.71it/s, Loss=12750.5840]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15103.2582\n",
      "Val Loss: 15368.9674\n",
      "MAE: 88.31\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.75it/s, Loss=5580.1816] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12691.3328\n",
      "Val Loss: 12440.4271\n",
      "MAE: 80.70\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.70it/s, Loss=14588.1611]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14626.9604\n",
      "Val Loss: 15566.5103\n",
      "MAE: 95.93\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.74it/s, Loss=18540.2324]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12790.0710\n",
      "Val Loss: 12195.4480\n",
      "MAE: 77.72\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=14720.8389]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13896.2719\n",
      "Val Loss: 14153.7042\n",
      "MAE: 84.84\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=11000.3047]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12648.2240\n",
      "Val Loss: 19999.2132\n",
      "MAE: 94.05\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=7634.4512] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14111.9219\n",
      "Val Loss: 13349.9398\n",
      "MAE: 80.14\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.63it/s, Loss=12659.7461]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12839.5552\n",
      "Val Loss: 13895.5213\n",
      "MAE: 79.95\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.62it/s, Loss=15959.1836]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11621.1715\n",
      "Val Loss: 11186.4165\n",
      "MAE: 74.05\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.76it/s, Loss=13164.2227]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9961.4461\n",
      "Val Loss: 11065.7458\n",
      "MAE: 74.22\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.72it/s, Loss=13711.0225]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9124.5119\n",
      "Val Loss: 10659.0329\n",
      "MAE: 70.08\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=8082.5566] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9164.1247\n",
      "Val Loss: 9452.4252\n",
      "MAE: 65.46\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.63it/s, Loss=19323.6582]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8234.6174\n",
      "Val Loss: 9203.9458\n",
      "MAE: 63.62\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=17844.7168]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7169.4415\n",
      "Val Loss: 9039.3700\n",
      "MAE: 63.09\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.56it/s, Loss=4371.0186] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6902.1733\n",
      "Val Loss: 9108.9032\n",
      "MAE: 65.14\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.67it/s, Loss=5139.2446] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7225.2841\n",
      "Val Loss: 8981.3601\n",
      "MAE: 63.80\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=6355.6934] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7110.6049\n",
      "Val Loss: 8771.6032\n",
      "MAE: 64.34\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.71it/s, Loss=8896.7773] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7144.2236\n",
      "Val Loss: 10628.1778\n",
      "MAE: 66.19\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.65it/s, Loss=3892.2854] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6981.3416\n",
      "Val Loss: 9885.5095\n",
      "MAE: 63.13\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=13593.6973]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5941.3330\n",
      "Val Loss: 8738.7350\n",
      "MAE: 60.29\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.73it/s, Loss=5091.1475] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6739.6593\n",
      "Val Loss: 8839.5363\n",
      "MAE: 64.91\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=7478.1865] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7035.6328\n",
      "Val Loss: 8574.2145\n",
      "MAE: 60.91\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.62it/s, Loss=7437.9102] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6462.3429\n",
      "Val Loss: 10082.7804\n",
      "MAE: 65.77\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.67it/s, Loss=7091.4688] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6361.0576\n",
      "Val Loss: 8031.6725\n",
      "MAE: 59.30\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.65it/s, Loss=4263.9404] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7532.7256\n",
      "Val Loss: 10266.9559\n",
      "MAE: 73.08\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 8031.6725\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/nutrition5k_experiments/inceptionv3_early_fusion_20251024_015043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### EARLY FUSION\n",
    "# Import the necessary modules\n",
    "import sys\n",
    "sys.path.append('/data/projects/punim0478/setiawand/Computer-Vision-COMP90086/src')\n",
    "\n",
    "from nutrition5k_inceptionv3_model import build_nutrition5k_model\n",
    "\n",
    "# Configure experiment settings\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "DROPOUT_RATE = 0.4\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "WARMUP_RATIO = 0.1\n",
    "MIN_LR_RATIO = 0.05\n",
    "FUSION_CHANNELS = 2048  # InceptionV3 output channels\n",
    "\n",
    "def train_nutrition5k_model(fusion_type='middle'):\n",
    "    \"\"\"Train the Nutrition5k model with InceptionV3 and specified fusion type\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TRAINING: Nutrition5k InceptionV3 + {fusion_type.capitalize()} Fusion\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model with specified fusion type\n",
    "    model = build_nutrition5k_model(\n",
    "        fusion=fusion_type,\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "    \n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"inceptionv3_{fusion_type}_fusion_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, 'nutrition5k_experiments', exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Save experiment configuration\n",
    "    config = {\n",
    "        'fusion': fusion_type,\n",
    "        'pretrained': False,\n",
    "        'dropout_rate': DROPOUT_RATE,\n",
    "        'fusion_channels': FUSION_CHANNELS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'img_size': IMG_SIZE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(exp_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run an experiment with middle fusion\n",
    "middle_fusion_results = train_nutrition5k_model(fusion_type='early')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db96b873",
   "metadata": {},
   "source": [
    "### InceptionV3 - Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ddb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: Nutrition5k InceptionV3 + Late Fusion\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 45,799,745\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0003\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=92137.3281] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99496.0301\n",
      "Val Loss: 107413.2869\n",
      "MAE: 240.63\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.59it/s, Loss=20197.7324] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 41417.1546\n",
      "Val Loss: 23518.8432\n",
      "MAE: 110.41\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.48it/s, Loss=12936.2207]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 18394.7451\n",
      "Val Loss: 27879.1521\n",
      "MAE: 130.08\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=5857.6758] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15631.6721\n",
      "Val Loss: 17150.6596\n",
      "MAE: 96.63\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.53it/s, Loss=16256.8613]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14657.0439\n",
      "Val Loss: 18234.3740\n",
      "MAE: 95.69\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=29184.6055]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16181.8207\n",
      "Val Loss: 18212.7725\n",
      "MAE: 101.95\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=14177.6338]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16528.9589\n",
      "Val Loss: 19769.3904\n",
      "MAE: 94.68\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.40it/s, Loss=9167.7754] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15326.8427\n",
      "Val Loss: 15101.5686\n",
      "MAE: 89.13\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=5764.5386] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12244.9910\n",
      "Val Loss: 13346.2350\n",
      "MAE: 83.84\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=7906.2188] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14183.1754\n",
      "Val Loss: 26943.3766\n",
      "MAE: 110.36\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=9812.9639] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12651.2474\n",
      "Val Loss: 12368.1356\n",
      "MAE: 80.38\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=24655.7402]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13272.9006\n",
      "Val Loss: 13379.9750\n",
      "MAE: 81.81\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.47it/s, Loss=15293.3789]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13347.6347\n",
      "Val Loss: 15332.9240\n",
      "MAE: 85.28\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.53it/s, Loss=12800.7051]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10389.0809\n",
      "Val Loss: 11364.2777\n",
      "MAE: 73.28\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=10389.8984]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11086.1946\n",
      "Val Loss: 13503.8838\n",
      "MAE: 79.48\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=4634.6675] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12062.0961\n",
      "Val Loss: 15197.5910\n",
      "MAE: 79.57\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.56it/s, Loss=11386.3691]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10094.7610\n",
      "Val Loss: 10928.9634\n",
      "MAE: 72.32\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.62it/s, Loss=16639.9902]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8841.2466\n",
      "Val Loss: 10273.5138\n",
      "MAE: 70.54\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.49it/s, Loss=14973.8633]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7842.5754\n",
      "Val Loss: 8621.5220\n",
      "MAE: 64.69\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=4790.6357] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7812.2845\n",
      "Val Loss: 10873.2357\n",
      "MAE: 70.87\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=7329.7334] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7748.6470\n",
      "Val Loss: 9369.9061\n",
      "MAE: 66.80\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=2818.6331] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6810.1954\n",
      "Val Loss: 8614.7345\n",
      "MAE: 64.43\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.49it/s, Loss=4565.0459] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6976.2430\n",
      "Val Loss: 9031.5828\n",
      "MAE: 64.74\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.43it/s, Loss=7315.9697] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7005.8437\n",
      "Val Loss: 8837.8805\n",
      "MAE: 64.08\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=3478.6108] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7402.5686\n",
      "Val Loss: 8897.0710\n",
      "MAE: 66.63\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.53it/s, Loss=4164.8110] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6720.7030\n",
      "Val Loss: 8451.3195\n",
      "MAE: 62.95\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=5311.6123] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7451.9909\n",
      "Val Loss: 9846.7700\n",
      "MAE: 69.83\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.47it/s, Loss=7311.1289] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5914.3422\n",
      "Val Loss: 7753.1898\n",
      "MAE: 61.30\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=9494.0742] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7779.3467\n",
      "Val Loss: 13598.2838\n",
      "MAE: 82.95\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.59it/s, Loss=7153.1699] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9569.8168\n",
      "Val Loss: 14570.7333\n",
      "MAE: 83.45\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=5844.6611] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8250.0567\n",
      "Val Loss: 11566.9276\n",
      "MAE: 69.32\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=8072.5889] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7908.1150\n",
      "Val Loss: 9551.1853\n",
      "MAE: 69.71\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=2906.7651] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6763.8853\n",
      "Val Loss: 7498.6955\n",
      "MAE: 59.51\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.46it/s, Loss=6910.6724] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8289.4109\n",
      "Val Loss: 11650.5973\n",
      "MAE: 71.26\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.48it/s, Loss=7934.6768] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7716.5857\n",
      "Val Loss: 9250.8389\n",
      "MAE: 61.81\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.56it/s, Loss=2937.8640] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6092.7816\n",
      "Val Loss: 7978.9293\n",
      "MAE: 59.75\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=9540.3496] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6387.2168\n",
      "Val Loss: 9294.3610\n",
      "MAE: 66.39\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=3309.8706] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6015.9126\n",
      "Val Loss: 8752.3340\n",
      "MAE: 59.10\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.51it/s, Loss=4846.8662] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5422.7444\n",
      "Val Loss: 8293.2926\n",
      "MAE: 57.32\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.52it/s, Loss=10166.2549]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5768.5268\n",
      "Val Loss: 10900.3926\n",
      "MAE: 71.02\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 7498.6955\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/nutrition5k_experiments/inceptionv3_late_fusion_20251024_020244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### EARLY FUSION\n",
    "# Import the necessary modules\n",
    "import sys\n",
    "sys.path.append('/data/projects/punim0478/setiawand/Computer-Vision-COMP90086/src')\n",
    "\n",
    "from nutrition5k_inceptionv3_model import build_nutrition5k_model\n",
    "\n",
    "# Configure experiment settings\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "DROPOUT_RATE = 0.4\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "WARMUP_RATIO = 0.1\n",
    "MIN_LR_RATIO = 0.05\n",
    "FUSION_CHANNELS = 2048  # InceptionV3 output channels\n",
    "\n",
    "def train_nutrition5k_model(fusion_type='middle'):\n",
    "    \"\"\"Train the Nutrition5k model with InceptionV3 and specified fusion type\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TRAINING: Nutrition5k InceptionV3 + {fusion_type.capitalize()} Fusion\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model with specified fusion type\n",
    "    model = build_nutrition5k_model(\n",
    "        fusion=fusion_type,\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "    \n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"inceptionv3_{fusion_type}_fusion_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, 'nutrition5k_experiments', exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Save experiment configuration\n",
    "    config = {\n",
    "        'fusion': fusion_type,\n",
    "        'pretrained': False,\n",
    "        'dropout_rate': DROPOUT_RATE,\n",
    "        'fusion_channels': FUSION_CHANNELS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'img_size': IMG_SIZE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(exp_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run an experiment with middle fusion\n",
    "middle_fusion_results = train_nutrition5k_model(fusion_type='late')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e3c01",
   "metadata": {},
   "source": [
    "### InceptionV3 - Middle + Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a722ff6",
   "metadata": {},
   "source": [
    "This section implements the food volume estimation method as described in the Nutrition5k paper. The method:\n",
    "\n",
    "1. **Estimates food volume from overhead depth images** using:\n",
    "   - Camera distance: 35.9 cm\n",
    "   - Per-pixel surface area: 5.957 × 10⁻³ cm²\n",
    "   \n",
    "2. **Uses binary foreground/background segmentation** to identify food pixels\n",
    "\n",
    "3. **Calculates volume** by summing per-pixel volumes (depth × surface_area) over all food pixels\n",
    "\n",
    "4. **Concatenates volume estimate** to the InceptionV3 backbone output before FC layers\n",
    "\n",
    "We implement three variants:\n",
    "- **Image-only**: Uses only RGB images (baseline)\n",
    "- **Image+Volume**: RGB + volume estimate as additional signal  \n",
    "- **Middle+Volume**: RGB + Depth fusion + volume estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e46544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: Nutrition5k InceptionV3 + IMAGE_VOLUME\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 21,916,833\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0006\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.28it/s, Loss=99318.9922] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99604.5156\n",
      "Val Loss: 107448.1609\n",
      "MAE: 240.71\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  5.90it/s, Loss=27212.8672] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 63577.8359\n",
      "Val Loss: 24757.2560\n",
      "MAE: 109.26\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.28it/s, Loss=21536.7402]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 21047.6365\n",
      "Val Loss: 18295.3270\n",
      "MAE: 96.29\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.44it/s, Loss=27675.7715]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16474.4804\n",
      "Val Loss: 18842.0287\n",
      "MAE: 96.13\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.33it/s, Loss=18595.8320]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14706.7234\n",
      "Val Loss: 18811.3113\n",
      "MAE: 88.86\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.49it/s, Loss=18142.2656]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14413.2615\n",
      "Val Loss: 12728.1906\n",
      "MAE: 73.60\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.49it/s, Loss=10410.6738]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14271.3644\n",
      "Val Loss: 16915.0480\n",
      "MAE: 86.64\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.40it/s, Loss=3845.6904] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11261.8414\n",
      "Val Loss: 12322.4708\n",
      "MAE: 75.59\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.35it/s, Loss=15812.2764]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11909.0745\n",
      "Val Loss: 15805.3332\n",
      "MAE: 84.78\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.35it/s, Loss=7558.3633] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9683.7176\n",
      "Val Loss: 10580.0962\n",
      "MAE: 69.44\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.43it/s, Loss=8729.1035] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9385.4864\n",
      "Val Loss: 8912.5723\n",
      "MAE: 63.01\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.62it/s, Loss=7250.2197] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8184.1507\n",
      "Val Loss: 9229.2757\n",
      "MAE: 65.64\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.51it/s, Loss=4372.3555] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7190.5738\n",
      "Val Loss: 9063.1473\n",
      "MAE: 62.50\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.56it/s, Loss=6169.8789] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6633.1344\n",
      "Val Loss: 8999.3006\n",
      "MAE: 62.75\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.50it/s, Loss=5244.7402] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6481.6600\n",
      "Val Loss: 8037.1015\n",
      "MAE: 59.31\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.48it/s, Loss=14404.2119]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8298.4505\n",
      "Val Loss: 11483.6100\n",
      "MAE: 66.88\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.34it/s, Loss=11080.8086]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7881.9119\n",
      "Val Loss: 10975.4653\n",
      "MAE: 68.88\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.44it/s, Loss=5914.3340] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7572.8723\n",
      "Val Loss: 8844.1845\n",
      "MAE: 64.86\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.28it/s, Loss=12906.9141]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6075.9087\n",
      "Val Loss: 8848.1346\n",
      "MAE: 63.39\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.42it/s, Loss=1840.6912] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5124.8709\n",
      "Val Loss: 8001.3758\n",
      "MAE: 56.63\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.42it/s, Loss=6674.5479] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6633.3299\n",
      "Val Loss: 9869.4169\n",
      "MAE: 63.28\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.39it/s, Loss=5856.6167] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5922.3994\n",
      "Val Loss: 8164.9982\n",
      "MAE: 57.55\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.42it/s, Loss=4248.4380] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6868.9295\n",
      "Val Loss: 13686.8138\n",
      "MAE: 72.39\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.28it/s, Loss=8814.5322] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8012.7733\n",
      "Val Loss: 11704.6879\n",
      "MAE: 73.09\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.47it/s, Loss=15043.5703]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7672.9970\n",
      "Val Loss: 7806.0816\n",
      "MAE: 56.99\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.42it/s, Loss=8293.2812] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6617.2126\n",
      "Val Loss: 12537.5695\n",
      "MAE: 71.71\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.32it/s, Loss=4698.1025] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8194.3460\n",
      "Val Loss: 13311.4873\n",
      "MAE: 75.60\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.32it/s, Loss=13278.1055]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8392.1834\n",
      "Val Loss: 9992.9852\n",
      "MAE: 64.08\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.24it/s, Loss=4275.8862] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5923.3065\n",
      "Val Loss: 7743.4460\n",
      "MAE: 55.87\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.27it/s, Loss=7370.0547] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6643.9705\n",
      "Val Loss: 12067.0591\n",
      "MAE: 68.68\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  6.18it/s, Loss=4696.9580] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7005.5259\n",
      "Val Loss: 11429.5898\n",
      "MAE: 68.84\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.42it/s, Loss=7130.9663] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6370.8517\n",
      "Val Loss: 14455.1641\n",
      "MAE: 76.53\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.31it/s, Loss=3075.8811] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5835.5243\n",
      "Val Loss: 10896.3757\n",
      "MAE: 71.29\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.38it/s, Loss=3918.4011] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5061.9165\n",
      "Val Loss: 8025.8195\n",
      "MAE: 57.00\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.37it/s, Loss=5859.2598] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4926.0381\n",
      "Val Loss: 8761.3339\n",
      "MAE: 59.76\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.42it/s, Loss=4316.6699] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4445.6550\n",
      "Val Loss: 7701.0904\n",
      "MAE: 53.51\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.41it/s, Loss=3331.4092] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5374.4937\n",
      "Val Loss: 8197.4740\n",
      "MAE: 63.06\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.43it/s, Loss=4128.9854]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4442.2072\n",
      "Val Loss: 8137.3096\n",
      "MAE: 58.84\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.38it/s, Loss=3062.8418] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4795.8385\n",
      "Val Loss: 7917.6565\n",
      "MAE: 59.56\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:13<00:00,  6.43it/s, Loss=4999.4717] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4722.3875\n",
      "Val Loss: 10296.3620\n",
      "MAE: 65.27\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 7701.0904\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/nutrition5k_experiments/inceptionv3_image_volume_20251024_125048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/data/projects/punim0478/setiawand/Computer-Vision-COMP90086/src')\n",
    "\n",
    "from nutrition5k_inceptionv3_model import build_nutrition5k_model\n",
    "\n",
    "# Configure experiment settings\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "DROPOUT_RATE = 0.4\n",
    "LEARNING_RATE = 4e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "WARMUP_RATIO = 0.1\n",
    "MIN_LR_RATIO = 0.05\n",
    "FUSION_CHANNELS = 2048  # InceptionV3 output channels\n",
    "\n",
    "# Training function with volume estimation support\n",
    "def train_nutrition5k_with_volume(fusion_type='image_volume'):\n",
    "    \"\"\"\n",
    "    Train the Nutrition5k model with volume estimation\n",
    "    \n",
    "    Args:\n",
    "        fusion_type: 'image_only', 'image_volume', 'middle', etc.\n",
    "        use_segmentation: Whether to use learned segmentation for volume estimation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TRAINING: Nutrition5k InceptionV3 + {fusion_type.upper()}\")\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model with volume estimation\n",
    "    use_volume = 'volume' in fusion_type\n",
    "    \n",
    "    model = build_nutrition5k_model(\n",
    "        fusion=fusion_type,\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "        use_volume=use_volume,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "    \n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"inceptionv3_{fusion_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, 'nutrition5k_experiments', exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Save experiment configuration\n",
    "    config = {\n",
    "        'fusion': fusion_type,\n",
    "        'use_volume': use_volume,\n",
    "        'pretrained': False,\n",
    "        'dropout_rate': DROPOUT_RATE,\n",
    "        'fusion_channels': FUSION_CHANNELS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'img_size': IMG_SIZE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(exp_dir, 'config.json'), 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "\n",
    "middle_fusion_results = train_nutrition5k_with_volume(fusion_type='image_volume')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd72f9b",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4badf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \"\"\"Dataset class for test set inference\"\"\"\n",
    "    \n",
    "    def __init__(self, test_root, img_size=224):\n",
    "        self.test_root = test_root\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Paths to subdirectories\n",
    "        self.color_dir = os.path.join(test_root, 'color')\n",
    "        self.depth_raw_dir = os.path.join(test_root, 'depth_raw')\n",
    "        \n",
    "        # Get all dish IDs from color directory\n",
    "        self.dish_ids = []\n",
    "        if os.path.exists(self.color_dir):\n",
    "            self.dish_ids = sorted([d for d in os.listdir(self.color_dir) \n",
    "                                  if os.path.isdir(os.path.join(self.color_dir, d))])\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Test color directory not found: {self.color_dir}\")\n",
    "        \n",
    "        print(f\"Found {len(self.dish_ids)} test samples\")\n",
    "        \n",
    "        # Color normalization (same as training)\n",
    "        self.color_normalize = T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        \n",
    "        # Validate test data\n",
    "        self.valid_indices = self._validate_test_data()\n",
    "        print(f\"Valid test samples: {len(self.valid_indices)}\")\n",
    "    \n",
    "    def _validate_test_data(self):\n",
    "        \"\"\"Validate test data and return valid indices\"\"\"\n",
    "        valid_indices = []\n",
    "        \n",
    "        for idx, dish_id in enumerate(self.dish_ids):\n",
    "            rgb_path = os.path.join(self.color_dir, dish_id, 'rgb.png')\n",
    "            depth_path = os.path.join(self.depth_raw_dir, dish_id, 'depth_raw.png')\n",
    "            \n",
    "            # Check if files exist\n",
    "            if not os.path.exists(rgb_path) or not os.path.exists(depth_path):\n",
    "                continue\n",
    "            \n",
    "            # Try to load images to check for corruption\n",
    "            try:\n",
    "                with Image.open(rgb_path) as img:\n",
    "                    img.verify()\n",
    "                with Image.open(depth_path) as img:\n",
    "                    img.verify()\n",
    "                valid_indices.append(idx)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return valid_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.valid_indices[idx]\n",
    "        dish_id = self.dish_ids[actual_idx]\n",
    "        \n",
    "        # Load images\n",
    "        rgb_path = os.path.join(self.color_dir, dish_id, 'rgb.png')\n",
    "        depth_path = os.path.join(self.depth_raw_dir, dish_id, 'depth_raw.png')\n",
    "        \n",
    "        rgb_img = Image.open(rgb_path).convert('RGB')\n",
    "        depth_img = Image.open(depth_path).convert('L')\n",
    "        \n",
    "        # Resize images (no augmentation for test)\n",
    "        rgb_img = TF.resize(rgb_img, (self.img_size, self.img_size))\n",
    "        depth_img = TF.resize(depth_img, (self.img_size, self.img_size))\n",
    "        \n",
    "        # Convert to tensors\n",
    "        rgb_tensor = TF.to_tensor(rgb_img)  # (3, H, W)\n",
    "        depth_tensor = TF.to_tensor(depth_img)  # (1, H, W)\n",
    "        \n",
    "        # Normalize RGB\n",
    "        rgb_tensor = self.color_normalize(rgb_tensor)\n",
    "        \n",
    "        # Normalize depth to [0, 1] range\n",
    "        depth_tensor = depth_tensor / 255.0\n",
    "        \n",
    "        return {\n",
    "            'rgb': rgb_tensor,\n",
    "            'depth': depth_tensor,\n",
    "            'dish_id': dish_id\n",
    "        }\n",
    "    \n",
    "    def get_all_dish_ids(self):\n",
    "        \"\"\"Get all dish IDs for complete submission\"\"\"\n",
    "        return self.dish_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322d3c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 32\n",
      "Best validation loss: 7366.6407\n",
      "Model loaded and set to evaluation mode!\n"
     ]
    }
   ],
   "source": [
    "from nutrition5k_inceptionv3_model import build_nutrition5k_model\n",
    "\n",
    "# Path to your best model\n",
    "model_path = '/data/projects/punim0478/setiawand/Computer-Vision-COMP90086/experiments/nutrition5k_experiments/inceptionv3_middle_fusion_20251024_003206/best_model.pth'\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "\n",
    "# Create model with same configuration\n",
    "model = build_nutrition5k_model(\n",
    "    fusion='middle',\n",
    "    pretrained=False,\n",
    "    dropout_rate=0.4,\n",
    "    fusion_channels=2048\n",
    ").to(device)\n",
    "\n",
    "# Load weights\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded model from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "    if 'val_loss' in checkpoint:\n",
    "        print(f\"Best validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(\"Loaded model state dict directly\")\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded and set to evaluation mode!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b8978aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 189 test samples\n",
      "Valid test samples: 189\n",
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 6/6 [00:01<00:00,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete! Predicted 189 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset\n",
    "test_root = '/data/projects/punim0478/setiawand/Computer-Vision-COMP90086/Nutrition5K/test'  # Update this path\n",
    "test_dataset = TestDataset(test_root=test_root, img_size=224)\n",
    "\n",
    "# Create data loader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Run inference\n",
    "predictions = {}\n",
    "model.eval()\n",
    "\n",
    "print(\"Running inference...\")\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Inference\"):\n",
    "        # Move to device\n",
    "        rgb = batch['rgb'].to(device)\n",
    "        depth = batch['depth'].to(device)\n",
    "        dish_ids = batch['dish_id']\n",
    "        \n",
    "        # Forward pass\n",
    "        calorie_pred = model(rgb, depth)\n",
    "        \n",
    "        # Convert predictions to CPU and store\n",
    "        calorie_pred = calorie_pred.cpu().numpy().flatten()\n",
    "        \n",
    "        for i, dish_id in enumerate(dish_ids):\n",
    "            predictions[dish_id] = float(calorie_pred[i])\n",
    "\n",
    "print(f\"Inference complete! Predicted {len(predictions)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c0d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Submission file saved: ../inceptionv3_submission.csv\n",
      "✓ Total predictions: 189\n",
      "✓ Format: ID,Value\n",
      "\n",
      "First 10 rows of submission:\n",
      "       ID       Value\n",
      "dish_3301 1044.153076\n",
      "dish_3302    9.835475\n",
      "dish_3303   36.430813\n",
      "dish_3304  172.032990\n",
      "dish_3305  444.484985\n",
      "dish_3306   13.134394\n",
      "dish_3307  527.778381\n",
      "dish_3308   70.698853\n",
      "dish_3309  479.417755\n",
      "dish_3310  143.995743\n",
      "\n",
      "Prediction Statistics:\n",
      "  Min:    7.17\n",
      "  Max:    1044.15\n",
      "  Mean:   235.59\n",
      "  Median: 195.93\n",
      "  Std:    187.75\n"
     ]
    }
   ],
   "source": [
    "# Prepare submission data in the exact format required\n",
    "all_dish_ids = test_dataset.get_all_dish_ids()\n",
    "submission_data = []\n",
    "\n",
    "for dish_id in sorted(all_dish_ids):\n",
    "    prediction = predictions.get(dish_id, 0.0)  # Default to 0.0 if missing\n",
    "    submission_data.append({\n",
    "        'ID': dish_id,\n",
    "        'Value': prediction\n",
    "    })\n",
    "\n",
    "# Create DataFrame with exact column names\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "\n",
    "# Save to CSV with the exact format (ID,Value)\n",
    "output_path = '../inceptionv3_submission.csv'\n",
    "submission_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Submission file saved: {output_path}\")\n",
    "print(f\"✓ Total predictions: {len(submission_data)}\")\n",
    "print(f\"✓ Format: ID,Value\")\n",
    "\n",
    "# Print first few rows to verify format\n",
    "print(f\"\\nFirst 10 rows of submission:\")\n",
    "print(submission_df.head(10).to_string(index=False))\n",
    "\n",
    "# Print statistics\n",
    "values = submission_df['Value'].values\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(f\"  Min:    {values.min():.2f}\")\n",
    "print(f\"  Max:    {values.max():.2f}\")\n",
    "print(f\"  Mean:   {values.mean():.2f}\")\n",
    "print(f\"  Median: {np.median(values):.2f}\")\n",
    "print(f\"  Std:    {values.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
