{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef3cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(789)\n",
    "np.random.seed(789)\n",
    "random.seed(789)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(789)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a5770",
   "metadata": {},
   "source": [
    "# 1. Model and Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0f056",
   "metadata": {},
   "source": [
    "## 1.1 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f943061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Implementation - Calorie Prediction Only (No Segmentation)\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    \"\"\"ResNet encoder that extracts feature maps\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder_type: str = 'resnet18', pretrained: bool = False, in_channels: int = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load appropriate ResNet\n",
    "        if encoder_type == 'resnet18':\n",
    "            resnet = models.resnet18(pretrained=pretrained)\n",
    "            self.out_channels = 512\n",
    "        elif encoder_type == 'resnet34':\n",
    "            resnet = models.resnet34(pretrained=pretrained)\n",
    "            self.out_channels = 512\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported encoder: {encoder_type}\")\n",
    "        \n",
    "        # Modify first conv if we have different input channels (e.g., 1 for depth)\n",
    "        if in_channels != 3:\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "            )\n",
    "        else:\n",
    "            self.conv1 = resnet.conv1\n",
    "        \n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        \n",
    "        # ResNet layers\n",
    "        self.layer1 = resnet.layer1  # Output: 64 channels\n",
    "        self.layer2 = resnet.layer2  # Output: 128 channels\n",
    "        self.layer3 = resnet.layer3  # Output: 256 channels\n",
    "        self.layer4 = resnet.layer4  # Output: 512 channels\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (B, C, H, W)\n",
    "        Returns:\n",
    "            Feature map (B, 512, H/32, W/32)\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class MiddleFusionModule(nn.Module):\n",
    "    \"\"\"Middle fusion: Concatenate RGB and Depth features, then merge with 1x1 conv\"\"\"\n",
    "    \n",
    "    def __init__(self, rgb_channels: int = 512, depth_channels: int = 512, output_channels: int = 512):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1x1 convolution to merge features\n",
    "        self.fusion_conv = nn.Conv2d(\n",
    "            rgb_channels + depth_channels,\n",
    "            output_channels,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, rgb_features, depth_features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rgb_features: (B, 512, H, W)\n",
    "            depth_features: (B, 512, H, W)\n",
    "        Returns:\n",
    "            Fused features: (B, 512, H, W)\n",
    "        \"\"\"\n",
    "        # Concatenate along channel dimension\n",
    "        fused = torch.cat([rgb_features, depth_features], dim=1)  # (B, 1024, H, W)\n",
    "        \n",
    "        # Apply 1x1 conv to reduce channels\n",
    "        fused = self.fusion_conv(fused)  # (B, 512, H, W)\n",
    "        fused = self.bn(fused)\n",
    "        fused = self.relu(fused)\n",
    "        \n",
    "        return fused\n",
    "\n",
    "\n",
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, in_channels: int = 512, dropout_rate: float = 0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.avgpool(x)  # (B, C, 1, 1)\n",
    "        x = self.fc_layers(x)  # (B, 1)\n",
    "        return x\n",
    "\n",
    "# Fusion factory function\n",
    "def get_fusion_module(fusion_name, rgb_channels, depth_channels, output_channels):\n",
    "    \"\"\"\n",
    "    Factory function to get fusion module\n",
    "    \n",
    "    Args:\n",
    "        fusion_name: Name of fusion module ('middle' or 'inception')\n",
    "        rgb_channels: Number of RGB feature channels\n",
    "        depth_channels: Number of depth feature channels\n",
    "        output_channels: Number of output channels\n",
    "    \n",
    "    Returns:\n",
    "        Fusion module\n",
    "    \"\"\"\n",
    "    if fusion_name == 'middle':\n",
    "        return MiddleFusionModule(\n",
    "            rgb_channels=rgb_channels,\n",
    "            depth_channels=depth_channels,\n",
    "            output_channels=output_channels\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown fusion module: {fusion_name}\")\n",
    "\n",
    "# Modify DualStreamCaloriePredictor to use different fusion modules\n",
    "class DualStreamCaloriePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Dual-stream CNN for calorie prediction using RGB and Depth images\n",
    "    Architecture: ResNet encoders + Fusion module + Regression head\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: str = 'resnet18',\n",
    "        fusion: str = 'middle',\n",
    "        fusion_channels: int = 512,\n",
    "        dropout_rate: float = 0.4,\n",
    "        pretrained: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # RGB and Depth encoders\n",
    "        self.rgb_encoder = ResNetEncoder(encoder, pretrained=pretrained, in_channels=3)\n",
    "        self.depth_encoder = ResNetEncoder(encoder, pretrained=pretrained, in_channels=1)\n",
    "        \n",
    "        # Create fusion module based on specified type\n",
    "        self.fusion = get_fusion_module(\n",
    "            fusion_name=fusion,\n",
    "            rgb_channels=self.rgb_encoder.out_channels,\n",
    "            depth_channels=self.depth_encoder.out_channels,\n",
    "            output_channels=fusion_channels\n",
    "        )\n",
    "        \n",
    "        # Regression head for calorie prediction\n",
    "        self.regression_head = RegressionHead(\n",
    "            in_channels=fusion_channels,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "    \n",
    "    def forward(self, rgb, depth):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rgb: RGB images (B, 3, H, W)\n",
    "            depth: Depth images (B, 1, H, W)\n",
    "        \n",
    "        Returns:\n",
    "            calorie_pred: Predicted calories (B, 1)\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        rgb_features = self.rgb_encoder(rgb)      # (B, 512, H/32, W/32)\n",
    "        depth_features = self.depth_encoder(depth)  # (B, 512, H/32, W/32)\n",
    "        \n",
    "        # Fuse features\n",
    "        fused_features = self.fusion(rgb_features, depth_features)  # (B, 512, H/32, W/32)\n",
    "        \n",
    "        # Predict calories\n",
    "        calorie_pred = self.regression_head(fused_features)  # (B, 1)\n",
    "        \n",
    "        return calorie_pred\n",
    "    \n",
    "    def get_num_parameters(self):\n",
    "        \"\"\"Get total number of trainable parameters\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "# Updated build_model function\n",
    "def build_model(encoder='resnet18', fusion='middle', regression_head='standard', \n",
    "                pretrained=False, dropout_rate=0.4, fusion_channels=512, **kwargs):\n",
    "    \"\"\"\n",
    "    Factory function to build models\n",
    "    \"\"\"\n",
    "    return DualStreamCaloriePredictor(\n",
    "        encoder=encoder,\n",
    "        fusion=fusion,\n",
    "        fusion_channels=fusion_channels,\n",
    "        dropout_rate=dropout_rate,\n",
    "        pretrained=pretrained\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4b3c9",
   "metadata": {},
   "source": [
    "## 1.2 Trainer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_warmup_cosine_scheduler(optimizer, warmup_steps, total_steps, min_lr_ratio=0.0):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        else:\n",
    "            progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "            return min_lr_ratio + (1.0 - min_lr_ratio) * 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to stop training when validation loss stops improving\"\"\"\n",
    "    \n",
    "    def __init__(self, patience: int = 10, min_delta: float = 0.0, mode: str = 'min'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience: Number of epochs with no improvement after which training will be stopped\n",
    "            min_delta: Minimum change to qualify as an improvement\n",
    "            mode: 'min' or 'max' - whether lower or higher metric is better\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "    def __call__(self, score, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            improved = score < (self.best_score - self.min_delta)\n",
    "        else:\n",
    "            improved = score > (self.best_score + self.min_delta)\n",
    "        \n",
    "        if improved:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                \n",
    "        return self.early_stop\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Training manager for calorie prediction\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        output_dir,\n",
    "        early_stopping_patience=15,\n",
    "        scheduler_step_on_batch=False\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        self.output_dir = output_dir\n",
    "        self.scheduler_step_on_batch = scheduler_step_on_batch\n",
    "        \n",
    "        # Early stopping\n",
    "        self.early_stopping = EarlyStopping(\n",
    "            patience=early_stopping_patience,\n",
    "            min_delta=0.1,\n",
    "            mode='min'\n",
    "        )\n",
    "        \n",
    "        # Tensorboard\n",
    "        self.writer = SummaryWriter(log_dir=os.path.join(output_dir, 'tensorboard'))\n",
    "        \n",
    "        # Tracking\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.best_metrics = {}\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=\"Training\")\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            # Move to device\n",
    "            rgb = batch['rgb'].to(self.device)\n",
    "            depth = batch['depth'].to(self.device)\n",
    "            calories = batch['calorie'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            calorie_pred = self.model(rgb, depth)\n",
    "            \n",
    "            # Compute loss (MSE for calorie prediction)\n",
    "            loss = self.criterion(calorie_pred.squeeze(), calories)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Update learning rate (if step_on_batch)\n",
    "            if self.scheduler_step_on_batch and self.scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def validate_epoch(self):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc=\"Validation\"):\n",
    "                # Move to device\n",
    "                rgb = batch['rgb'].to(self.device)\n",
    "                depth = batch['depth'].to(self.device)\n",
    "                calories = batch['calorie'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                calorie_pred = self.model(rgb, depth)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = self.criterion(calorie_pred.squeeze(), calories)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                # Store predictions and targets for metrics\n",
    "                all_predictions.extend(calorie_pred.squeeze().cpu().numpy())\n",
    "                all_targets.extend(calories.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_loss = total_loss / len(self.val_loader)\n",
    "        predictions = np.array(all_predictions)\n",
    "        targets = np.array(all_targets)\n",
    "        \n",
    "        mae = np.mean(np.abs(predictions - targets))\n",
    "        \n",
    "        return avg_loss, mae\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        \"\"\"Full training loop\"\"\"\n",
    "        print(f\"Starting training for {num_epochs} epochs...\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            \n",
    "            # Train\n",
    "            train_loss = self.train_epoch()\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, mae = self.validate_epoch()\n",
    "            \n",
    "            # Update learning rate (if not step_on_batch)\n",
    "            if not self.scheduler_step_on_batch and self.scheduler:\n",
    "                self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Log metrics\n",
    "            self.writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "            self.writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "            self.writer.add_scalar('MAE', mae, epoch)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.best_metrics = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'val_loss': val_loss,\n",
    "                    'mae': mae,\n",
    "                }\n",
    "                \n",
    "                # Save model checkpoint\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_loss': val_loss,\n",
    "                    'mae': mae,\n",
    "                }, os.path.join(self.output_dir, 'best_model.pth'))\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f\"Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"MAE: {mae:.2f}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.early_stopping(val_loss, epoch):\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                print(f\"Best epoch: {self.early_stopping.best_epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        self.writer.close()\n",
    "        print(f\"\\nTraining completed!\")\n",
    "        print(f\"Best validation loss: {self.best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f2e22",
   "metadata": {},
   "source": [
    "# 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0efa3",
   "metadata": {},
   "source": [
    "## 2.1 Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b386b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Implementation\n",
    "class Nutrition5KDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for Nutrition5K with multi-modal inputs (RGB + Depth)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path: str,\n",
    "        data_root: str,\n",
    "        split: str = 'train',\n",
    "        augment: bool = True,\n",
    "        img_size: int = 224,\n",
    "    ):\n",
    "        self.data_root = data_root\n",
    "        self.split = split\n",
    "        self.augment = augment\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Load CSV\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        if 'Value' in self.df.columns and 'calories' not in self.df.columns:\n",
    "            self.df = self.df.rename(columns={'Value': 'calories'})\n",
    "        if 'calories' not in self.df.columns:\n",
    "            raise ValueError(\"CSV file must contain a 'calories' column or a 'Value' column that can be renamed\")\n",
    "        self.df = self.df[self.df['calories'] < 3000].reset_index(drop=True)\n",
    "                \n",
    "        self.color_dir = os.path.join(data_root, 'color')\n",
    "        self.depth_raw_dir = os.path.join(data_root, 'depth_raw')\n",
    "        \n",
    "        self.valid_indices = self._validate_dataset()\n",
    "        print(f\"Loaded {len(self.valid_indices)} valid samples out of {len(self.df)}\")\n",
    "        \n",
    "        # Color normalization (ImageNet stats as baseline)\n",
    "        self.color_normalize = T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        \n",
    "    def _validate_dataset(self):\n",
    "        \"\"\"This method ensure that the code don't break when there are corrupted images.\"\"\"\"\n",
    "        valid_indices = []\n",
    "        \n",
    "        for idx in range(len(self.df)):\n",
    "            dish_id = self.df.iloc[idx]['ID']\n",
    "            \n",
    "            rgb_path = os.path.join(self.color_dir, dish_id, 'rgb.png')\n",
    "            depth_path = os.path.join(self.depth_raw_dir, dish_id, 'depth_raw.png')\n",
    "            \n",
    "            # Check if files exist\n",
    "            if not os.path.exists(rgb_path):\n",
    "                continue\n",
    "            if not os.path.exists(depth_path):\n",
    "                continue\n",
    "            \n",
    "            # Try to load images to check for corruption\n",
    "            try:\n",
    "                with Image.open(rgb_path) as img:\n",
    "                    img.verify()\n",
    "                with Image.open(depth_path) as img:\n",
    "                    img.verify()\n",
    "                valid_indices.append(idx)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "        return valid_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def _load_image_safe(self, path: str, mode: str = 'RGB') -> Optional[Image.Image]:\n",
    "        \"\"\"Safely load an image with error handling\"\"\"\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                return img.convert(mode).copy()\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _apply_augmentation(self, rgb_img, depth_img):\n",
    "        \"\"\"Apply geometric augmentation only (no color changes)\"\"\"\n",
    "        if not self.augment:\n",
    "            return rgb_img, depth_img\n",
    "        \n",
    "        # Convert to tensors first\n",
    "        rgb_tensor = TF.to_tensor(rgb_img)\n",
    "        depth_tensor = TF.to_tensor(depth_img)\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if random.random() > 0.5:\n",
    "            rgb_tensor = TF.hflip(rgb_tensor)\n",
    "            depth_tensor = TF.hflip(depth_tensor)\n",
    "        \n",
    "        # Random rotation (±15 degrees)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            rgb_tensor = TF.rotate(rgb_tensor, angle)\n",
    "            depth_tensor = TF.rotate(depth_tensor, angle)\n",
    "        \n",
    "        # Random resized crop\n",
    "        if random.random() > 0.4:  # 60% probability\n",
    "            i, j, h, w = T.RandomResizedCrop.get_params(\n",
    "                rgb_tensor, scale=(0.75, 1.0), ratio=(0.9, 1.1)\n",
    "            )\n",
    "            rgb_tensor = TF.resized_crop(rgb_tensor, i, j, h, w, (self.img_size, self.img_size))\n",
    "            depth_tensor = TF.resized_crop(depth_tensor, i, j, h, w, (self.img_size, self.img_size))\n",
    "        \n",
    "        # Convert back to PIL\n",
    "        rgb_img = TF.to_pil_image(rgb_tensor)\n",
    "        depth_img = TF.to_pil_image(depth_tensor)\n",
    "        \n",
    "        return rgb_img, depth_img\n",
    "    \n",
    "    def _resize_and_center_crop(self, img, target_size: int = 256):\n",
    "        \"\"\"\n",
    "        Resize and center crop image to target_size x target_size\n",
    "        Matches the preprocessing in the Nutrition5k paper\n",
    "        \n",
    "        Args:\n",
    "            img: PIL Image\n",
    "            target_size: Target size (default 256x256 as per paper)\n",
    "        \n",
    "        Returns:\n",
    "            Cropped PIL Image\n",
    "        \"\"\"\n",
    "        # Get original dimensions\n",
    "        width, height = img.size\n",
    "        \n",
    "        # Resize so the shorter side is target_size\n",
    "        if width < height:\n",
    "            new_width = target_size\n",
    "            new_height = int(target_size * height / width)\n",
    "        else:\n",
    "            new_height = target_size\n",
    "            new_width = int(target_size * width / height)\n",
    "        \n",
    "        img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "        \n",
    "        # Center crop to target_size x target_size\n",
    "        left = (new_width - target_size) // 2\n",
    "        top = (new_height - target_size) // 2\n",
    "        right = left + target_size\n",
    "        bottom = top + target_size\n",
    "        \n",
    "        img = img.crop((left, top, right, bottom))\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get a single sample\"\"\"\n",
    "        actual_idx = self.valid_indices[idx]\n",
    "        row = self.df.iloc[actual_idx]\n",
    "        \n",
    "        dish_id = row['ID']\n",
    "        calorie = float(row['calories'])\n",
    "        \n",
    "        # Load images\n",
    "        rgb_path = os.path.join(self.color_dir, dish_id, 'rgb.png')\n",
    "        depth_path = os.path.join(self.depth_raw_dir, dish_id, 'depth_raw.png')\n",
    "        \n",
    "        rgb_img = self._load_image_safe(rgb_path, 'RGB')\n",
    "        depth_img = self._load_image_safe(depth_path, 'L')  # Grayscale for depth\n",
    "        \n",
    "        # Fallback: return a black image\n",
    "        if rgb_img is None or depth_img is None:\n",
    "            rgb_img = Image.new('RGB', (self.img_size, self.img_size), (0, 0, 0))\n",
    "            depth_img = Image.new('L', (self.img_size, self.img_size), 0)\n",
    "        \n",
    "        # Apply augmentation\n",
    "        rgb_img, depth_img = self._apply_augmentation(rgb_img, depth_img)\n",
    "        \n",
    "        # Resize and center crop to match paper preprocessing (256x256)\n",
    "        rgb_img = self._resize_and_center_crop(rgb_img, target_size=self.img_size)\n",
    "        depth_img = self._resize_and_center_crop(depth_img, target_size=self.img_size)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        rgb_tensor = TF.to_tensor(rgb_img)  # (3, H, W)\n",
    "        depth_tensor = TF.to_tensor(depth_img)  # (1, H, W)\n",
    "        \n",
    "        # Normalize RGB\n",
    "        rgb_tensor = self.color_normalize(rgb_tensor)\n",
    "        \n",
    "        # Normalize depth (0-1 range, assuming depth is already in reasonable range)\n",
    "        depth_tensor = depth_tensor / 255.0\n",
    "        \n",
    "        return {\n",
    "            'dish_id': dish_id,\n",
    "            'rgb': rgb_tensor,\n",
    "            'depth': depth_tensor,\n",
    "            'calorie': torch.tensor(calorie, dtype=torch.float32)\n",
    "        }\n",
    "\n",
    "\n",
    "def create_train_val_split(csv_path: str, val_ratio: float = 0.15, random_seed: int = 42):\n",
    "    \"\"\"\n",
    "    Create train/validation split CSV files\n",
    "    \"\"\"\n",
    "    # Read original CSV\n",
    "    df = pd.read_csv(csv_path)    \n",
    "    \n",
    "    # Shuffle with fixed seed\n",
    "    df_shuffled = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "    \n",
    "    # Split\n",
    "    val_size = int(len(df_shuffled) * val_ratio)\n",
    "    train_df = df_shuffled[val_size:]\n",
    "    val_df = df_shuffled[:val_size]\n",
    "    \n",
    "    # Save temporary CSV files\n",
    "    base_dir = os.path.dirname(csv_path)\n",
    "    train_csv = os.path.join(base_dir, 'train_split.csv')\n",
    "    val_csv = os.path.join(base_dir, 'val_split.csv')\n",
    "    \n",
    "    train_df.to_csv(train_csv, index=False)\n",
    "    val_df.to_csv(val_csv, index=False)\n",
    "    \n",
    "    return train_csv, val_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980752c9",
   "metadata": {},
   "source": [
    "## 2.2 Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Data root: ../Nutrition5K/train\n",
      "  CSV path: ../Nutrition5K/nutrition5k_train.csv\n",
      "  Output directory: ../experiments\n",
      "  Batch size: 32\n",
      "  Number of epochs: 40\n",
      "  Image size: 256\n",
      "  Workers: 4\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Update these paths to match your setup\n",
    "DATA_ROOT = './Nutrition5K/Nutrition5K/train'  # Path to training data directory\n",
    "CSV_PATH = './Nutrition5K/Nutrition5K/nutrition5k_train.csv'  # Path to training CSV\n",
    "OUTPUT_DIR = './experiments'  # Directory to save experiment results\n",
    "\n",
    "# Global training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40\n",
    "VAL_RATIO = 0.15\n",
    "IMG_SIZE = 256\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Data root: {DATA_ROOT}\")\n",
    "print(f\"  CSV path: {CSV_PATH}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Number of epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Image size: {IMG_SIZE}\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947c256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation split...\n",
      "Train CSV: ../Nutrition5K/train_split.csv\n",
      "Validation CSV: ../Nutrition5K/val_split.csv\n",
      "Loaded 2804 valid samples out of 2805\n",
      "\n",
      "Dataset loaded successfully!\n",
      "Training samples: 2804\n",
      "RGB shape: torch.Size([3, 256, 256])\n",
      "Depth shape: torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Create train/validation split\n",
    "print(\"Creating train/validation split...\")\n",
    "train_csv, val_csv = create_train_val_split(\n",
    "    CSV_PATH,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Train CSV: {train_csv}\")\n",
    "print(f\"Validation CSV: {val_csv}\")\n",
    "\n",
    "# Load a sample to check data\n",
    "sample_dataset = Nutrition5KDataset(\n",
    "    csv_path=train_csv,\n",
    "    data_root=DATA_ROOT,\n",
    "    split='train',\n",
    "    augment=False,  # No augmentation for checking\n",
    "    img_size=IMG_SIZE,\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Training samples: {len(sample_dataset)}\")\n",
    "print(f\"RGB shape: {sample_dataset[0]['rgb'].shape}\")\n",
    "print(f\"Depth shape: {sample_dataset[0]['depth'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6f3b0",
   "metadata": {},
   "source": [
    "# 3. Experiments\n",
    "\n",
    "We'll conduct experiments to compare different encoder architectures with and without data augmentation.\n",
    "\n",
    "**Architecture**: Dual-stream CNN with middle fusion\n",
    "- **RGB encoder**: ResNet (18 or 34)\n",
    "- **Depth encoder**: ResNet (18 or 34) \n",
    "- **Fusion**: Standard middle fusion (concatenate + 1x1 conv)\n",
    "\n",
    "**Experiments**:\n",
    "1. ResNet-18 without augmentation (baseline)\n",
    "2. ResNet-18 with geometric augmentation\n",
    "3. ResNet-34 without augmentation\n",
    "4. ResNet-34 with geometric augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced54ebe",
   "metadata": {},
   "source": [
    "## 3.1 Resnet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77258dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Hyperparameteres\n",
    "DROPOUT_RATE = 0.3\n",
    "FUSION_CHANNELS = 512\n",
    "LEARNING_RATE = 8e-4\n",
    "WEIGHT_DECAY = 1e-6\n",
    "EARLY_STOPPING_PATIENCE = 7\n",
    "WARMUP_RATIO = 0.1\n",
    "MIN_LR_RATIO = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c14a3",
   "metadata": {},
   "source": [
    "### 3.1.1 No Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40330f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-18 + Middle Fusion (No Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 22,872,577\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=133763.1250]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99588.1862\n",
      "Val Loss: 107512.8083\n",
      "MAE: 240.83\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.20it/s, Loss=141186.5469]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 93442.4327\n",
      "Val Loss: 103962.4995\n",
      "MAE: 237.11\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=99093.0859] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 86276.3308\n",
      "Val Loss: 98197.5698\n",
      "MAE: 230.58\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.23it/s, Loss=111384.7266]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 84149.6715\n",
      "Val Loss: 88746.1426\n",
      "MAE: 219.59\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.23it/s, Loss=28057.3594] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 75295.6496\n",
      "Val Loss: 92595.2842\n",
      "MAE: 223.49\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.35it/s, Loss=46992.6055] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 61697.3167\n",
      "Val Loss: 91651.7266\n",
      "MAE: 224.38\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=60788.6055]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 53400.3644\n",
      "Val Loss: 62524.8992\n",
      "MAE: 185.24\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.27it/s, Loss=34053.6484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 45799.7142\n",
      "Val Loss: 24355.4155\n",
      "MAE: 108.24\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.20it/s, Loss=27366.5625]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 32245.2867\n",
      "Val Loss: 22714.7631\n",
      "MAE: 108.30\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=41695.0000]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 25916.9160\n",
      "Val Loss: 29127.6378\n",
      "MAE: 119.48\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.16it/s, Loss=46365.9688]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 23139.5869\n",
      "Val Loss: 22053.3058\n",
      "MAE: 102.53\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=11850.5859]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 21686.7587\n",
      "Val Loss: 23139.7461\n",
      "MAE: 105.16\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=12574.7012]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 20232.6971\n",
      "Val Loss: 24064.0271\n",
      "MAE: 109.80\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.25it/s, Loss=20526.3574]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19758.3131\n",
      "Val Loss: 18914.3069\n",
      "MAE: 93.01\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=6123.2905] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16014.0262\n",
      "Val Loss: 14381.4912\n",
      "MAE: 84.00\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.10it/s, Loss=9073.8311] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11504.8771\n",
      "Val Loss: 12995.8126\n",
      "MAE: 78.00\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.17it/s, Loss=7422.2266] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11147.3752\n",
      "Val Loss: 21229.2983\n",
      "MAE: 93.32\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=5081.7520] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8305.5386\n",
      "Val Loss: 12627.0216\n",
      "MAE: 73.45\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.26it/s, Loss=6787.8247] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7987.3262\n",
      "Val Loss: 16497.1763\n",
      "MAE: 83.85\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.18it/s, Loss=6696.3540] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6417.7676\n",
      "Val Loss: 11754.7650\n",
      "MAE: 71.26\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.20it/s, Loss=10333.9219]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5866.7414\n",
      "Val Loss: 15421.7828\n",
      "MAE: 81.27\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.24it/s, Loss=5702.7783] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4544.9265\n",
      "Val Loss: 11149.9972\n",
      "MAE: 69.17\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.22it/s, Loss=5078.2197] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4773.5788\n",
      "Val Loss: 11223.6857\n",
      "MAE: 69.60\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.29it/s, Loss=8156.5493] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3865.6909\n",
      "Val Loss: 11224.7352\n",
      "MAE: 68.30\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.30it/s, Loss=806.0511]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3399.2716\n",
      "Val Loss: 10764.9377\n",
      "MAE: 68.89\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=1323.5074] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2947.6614\n",
      "Val Loss: 10486.2951\n",
      "MAE: 66.10\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=1762.6411]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2471.1973\n",
      "Val Loss: 10716.0076\n",
      "MAE: 65.75\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.38it/s, Loss=2050.8726] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3069.4038\n",
      "Val Loss: 10138.0582\n",
      "MAE: 64.78\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.27it/s, Loss=2013.9670] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2423.1852\n",
      "Val Loss: 10326.1784\n",
      "MAE: 65.28\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.33it/s, Loss=4890.8232] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2742.4033\n",
      "Val Loss: 10311.3268\n",
      "MAE: 64.67\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.15it/s, Loss=863.5477]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2687.8933\n",
      "Val Loss: 9637.1174\n",
      "MAE: 64.59\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.24it/s, Loss=1831.1860] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2347.0324\n",
      "Val Loss: 10456.0297\n",
      "MAE: 65.15\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.24it/s, Loss=978.8034]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2447.3693\n",
      "Val Loss: 9988.2896\n",
      "MAE: 66.15\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=1020.9728] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2858.6214\n",
      "Val Loss: 10273.5074\n",
      "MAE: 65.81\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.15it/s, Loss=1495.0374] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2467.6893\n",
      "Val Loss: 9509.0767\n",
      "MAE: 63.78\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.28it/s, Loss=628.3477]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2286.3173\n",
      "Val Loss: 10011.1221\n",
      "MAE: 64.81\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.18it/s, Loss=1538.4891] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2130.9190\n",
      "Val Loss: 9982.3984\n",
      "MAE: 64.79\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.12it/s, Loss=2675.0352] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2215.4360\n",
      "Val Loss: 10430.9554\n",
      "MAE: 64.50\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.32it/s, Loss=4496.9961] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2082.9309\n",
      "Val Loss: 9938.9886\n",
      "MAE: 63.33\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.33it/s, Loss=695.4222]  \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2364.3041\n",
      "Val Loss: 9860.9779\n",
      "MAE: 63.48\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 9509.0767\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp1_resnet18_no_aug_20251023_115441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-18 without Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-18 baseline (no augmentation)\n",
    "def train_resnet18_no_aug():\n",
    "    \"\"\"Train ResNet-18 with standard middle fusion, no data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-18 + Middle Fusion (No Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (no augmentation)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,  # No augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-18 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet18',\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "        use_segmentation=False  # Calorie prediction only\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "        \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp1_resnet18_no_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet18_no_aug_results = train_resnet18_no_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706592e",
   "metadata": {},
   "source": [
    "### 3.1.2 Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f015d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-18 + Middle Fusion (With Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 22,872,577\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.53it/s, Loss=85079.6875] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99051.7583\n",
      "Val Loss: 107375.8743\n",
      "MAE: 240.59\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.73it/s, Loss=90859.1875] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 92092.3763\n",
      "Val Loss: 89712.8545\n",
      "MAE: 217.80\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=106267.1406]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 80478.5505\n",
      "Val Loss: 87209.2805\n",
      "MAE: 217.54\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.56it/s, Loss=28713.6836] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 67525.8587\n",
      "Val Loss: 62231.3778\n",
      "MAE: 183.26\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=46846.4766] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 51258.9550\n",
      "Val Loss: 52674.6289\n",
      "MAE: 164.88\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  5.81it/s, Loss=32966.6562]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 39434.6136\n",
      "Val Loss: 41577.8690\n",
      "MAE: 143.61\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=15293.2910]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 35792.9151\n",
      "Val Loss: 34405.6172\n",
      "MAE: 129.27\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.69it/s, Loss=13171.5469]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 34169.2190\n",
      "Val Loss: 34256.6227\n",
      "MAE: 128.45\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.71it/s, Loss=62203.7422]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 32442.9426\n",
      "Val Loss: 25855.3765\n",
      "MAE: 109.53\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.73it/s, Loss=10341.1270]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 30892.9986\n",
      "Val Loss: 26920.1313\n",
      "MAE: 111.00\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.69it/s, Loss=9082.0469] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 23164.5244\n",
      "Val Loss: 22798.4934\n",
      "MAE: 109.95\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.77it/s, Loss=18253.8965]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 20198.7868\n",
      "Val Loss: 19570.6440\n",
      "MAE: 93.34\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  5.85it/s, Loss=23779.0977]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19983.7109\n",
      "Val Loss: 21073.9814\n",
      "MAE: 99.18\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=21315.0508]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16180.7460\n",
      "Val Loss: 16609.2760\n",
      "MAE: 88.62\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.77it/s, Loss=12850.5508]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14903.0190\n",
      "Val Loss: 17341.5691\n",
      "MAE: 89.21\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=12160.0850]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15465.6358\n",
      "Val Loss: 14978.9188\n",
      "MAE: 83.28\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.71it/s, Loss=5302.0918] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13682.1568\n",
      "Val Loss: 15086.6279\n",
      "MAE: 87.54\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=7335.4014] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12730.4589\n",
      "Val Loss: 14327.3149\n",
      "MAE: 80.47\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.70it/s, Loss=6568.0122] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14864.4008\n",
      "Val Loss: 14101.0120\n",
      "MAE: 81.60\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=23456.0117]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13990.6148\n",
      "Val Loss: 14978.9472\n",
      "MAE: 87.05\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:14<00:00,  5.85it/s, Loss=3628.8484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11979.8724\n",
      "Val Loss: 14753.5390\n",
      "MAE: 80.00\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=16214.7764]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11947.5883\n",
      "Val Loss: 28577.6626\n",
      "MAE: 128.53\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.72it/s, Loss=9879.6221] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10679.9352\n",
      "Val Loss: 10907.9683\n",
      "MAE: 73.49\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.70it/s, Loss=15936.9922]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10730.9533\n",
      "Val Loss: 12514.4612\n",
      "MAE: 75.19\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.73it/s, Loss=12725.4805]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13483.8592\n",
      "Val Loss: 22171.8800\n",
      "MAE: 97.76\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.77it/s, Loss=10055.9473]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11926.3028\n",
      "Val Loss: 11966.0764\n",
      "MAE: 78.20\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.70it/s, Loss=12188.3887]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12080.6302\n",
      "Val Loss: 19402.6888\n",
      "MAE: 93.71\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=8683.4180] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12543.2637\n",
      "Val Loss: 14072.2663\n",
      "MAE: 81.51\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.75it/s, Loss=14817.7559]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11841.4046\n",
      "Val Loss: 11159.2817\n",
      "MAE: 72.23\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.63it/s, Loss=8485.0615] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10617.0792\n",
      "Val Loss: 11197.8942\n",
      "MAE: 70.36\n",
      "Early stopping triggered after 30 epochs\n",
      "Best epoch: 23\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 10907.9683\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp2_resnet18_with_aug_20251023_120817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-18 with Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-18 with geometric augmentation\n",
    "def train_resnet18_with_aug():\n",
    "    \"\"\"Train ResNet-18 with standard middle fusion and geometric data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-18 + Middle Fusion (With Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (with augmentation for training)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=True,  # Enable geometric augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-18 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet18',\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "        use_segmentation=False  # Calorie prediction only\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp2_resnet18_with_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet18_with_aug_results = train_resnet18_with_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3a407",
   "metadata": {},
   "source": [
    "## 3.2 Resnet-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afc023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT_RATE = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccdf09",
   "metadata": {},
   "source": [
    "### 3.2.1 No Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ab59db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-34 + Middle Fusion (No Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 43,088,897\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.14it/s, Loss=100307.0469]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 98698.4380\n",
      "Val Loss: 107480.8511\n",
      "MAE: 240.78\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.03it/s, Loss=115505.5078]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 93298.1988\n",
      "Val Loss: 94860.5649\n",
      "MAE: 225.05\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.13it/s, Loss=97543.1484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 78814.7641\n",
      "Val Loss: 75482.5867\n",
      "MAE: 198.21\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.02it/s, Loss=46035.8828] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 63182.2442\n",
      "Val Loss: 67355.9116\n",
      "MAE: 188.14\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.10it/s, Loss=34015.9844]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 48316.3558\n",
      "Val Loss: 44795.5026\n",
      "MAE: 151.35\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.96it/s, Loss=27088.8945]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 39746.4579\n",
      "Val Loss: 101420.4907\n",
      "MAE: 230.74\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:11<00:00,  7.25it/s, Loss=32450.6348]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 29236.0380\n",
      "Val Loss: 26153.1317\n",
      "MAE: 114.16\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.16it/s, Loss=27458.8535]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 22065.8771\n",
      "Val Loss: 26824.6976\n",
      "MAE: 112.60\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.15it/s, Loss=38509.7695]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 18690.6027\n",
      "Val Loss: 18364.3469\n",
      "MAE: 91.84\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.96it/s, Loss=8189.1870] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 16459.1131\n",
      "Val Loss: 23371.7727\n",
      "MAE: 103.03\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.94it/s, Loss=10984.0146]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14646.5586\n",
      "Val Loss: 14422.5637\n",
      "MAE: 82.67\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.05it/s, Loss=9203.7559] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13891.2966\n",
      "Val Loss: 25593.7811\n",
      "MAE: 113.19\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=13003.4951]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14939.9415\n",
      "Val Loss: 14794.3045\n",
      "MAE: 82.83\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.89it/s, Loss=10545.8398]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12406.2784\n",
      "Val Loss: 19018.4198\n",
      "MAE: 92.15\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.94it/s, Loss=8548.8857] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13727.4712\n",
      "Val Loss: 14259.7208\n",
      "MAE: 84.05\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.02it/s, Loss=36374.4219]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11469.9134\n",
      "Val Loss: 20453.0985\n",
      "MAE: 104.23\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.99it/s, Loss=16884.9199]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11314.3521\n",
      "Val Loss: 12779.0828\n",
      "MAE: 76.06\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=25691.1680]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12437.8630\n",
      "Val Loss: 13685.8074\n",
      "MAE: 88.04\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.91it/s, Loss=12364.6943]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11531.3536\n",
      "Val Loss: 16079.4240\n",
      "MAE: 86.28\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=6178.0864] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9448.1288\n",
      "Val Loss: 11009.8374\n",
      "MAE: 73.60\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.14it/s, Loss=20019.0801]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9207.7607\n",
      "Val Loss: 11962.1297\n",
      "MAE: 73.78\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.89it/s, Loss=17639.1445]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9813.5774\n",
      "Val Loss: 12778.6039\n",
      "MAE: 85.70\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=14909.9268]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10323.5442\n",
      "Val Loss: 13187.3307\n",
      "MAE: 78.38\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.11it/s, Loss=9893.2422] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9807.8190\n",
      "Val Loss: 24089.0463\n",
      "MAE: 105.49\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.13it/s, Loss=4728.5957] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8599.6537\n",
      "Val Loss: 11012.7349\n",
      "MAE: 72.33\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.06it/s, Loss=7365.0635] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 7456.4367\n",
      "Val Loss: 10319.1408\n",
      "MAE: 73.22\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.98it/s, Loss=6135.0625] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6794.7576\n",
      "Val Loss: 10980.3264\n",
      "MAE: 71.21\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.23it/s, Loss=9630.8418] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6846.5313\n",
      "Val Loss: 10542.8580\n",
      "MAE: 70.73\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=8346.2324] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6120.3744\n",
      "Val Loss: 10586.5872\n",
      "MAE: 71.17\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.09it/s, Loss=3144.8523] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5767.9688\n",
      "Val Loss: 10592.2169\n",
      "MAE: 70.01\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.05it/s, Loss=3549.7461] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5589.9075\n",
      "Val Loss: 9911.6910\n",
      "MAE: 69.30\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.00it/s, Loss=6178.6987] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4955.1105\n",
      "Val Loss: 9756.2419\n",
      "MAE: 66.65\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.00it/s, Loss=5042.2383] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5144.2286\n",
      "Val Loss: 9133.4005\n",
      "MAE: 66.62\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.01it/s, Loss=2124.5842] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5153.8232\n",
      "Val Loss: 10263.6432\n",
      "MAE: 67.77\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.07it/s, Loss=3494.1531] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4622.9021\n",
      "Val Loss: 9445.4597\n",
      "MAE: 67.23\n",
      "\n",
      "Epoch 36/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.03it/s, Loss=6312.3218] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4337.2332\n",
      "Val Loss: 9587.0288\n",
      "MAE: 66.16\n",
      "\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.10it/s, Loss=3321.8247] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4557.4898\n",
      "Val Loss: 9253.1733\n",
      "MAE: 66.74\n",
      "\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  6.95it/s, Loss=5787.7773] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4288.3274\n",
      "Val Loss: 9847.6848\n",
      "MAE: 66.14\n",
      "\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.13it/s, Loss=16884.8047]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4522.8226\n",
      "Val Loss: 9699.7839\n",
      "MAE: 65.64\n",
      "\n",
      "Epoch 40/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:12<00:00,  7.14it/s, Loss=3016.7654] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4215.9819\n",
      "Val Loss: 9186.5228\n",
      "MAE: 66.61\n",
      "Early stopping triggered after 40 epochs\n",
      "Best epoch: 33\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 9133.4005\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp3_resnet34_no_aug_20251023_122720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-34 without Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-34 baseline (no augmentation)\n",
    "def train_resnet34_no_aug():\n",
    "    \"\"\"Train ResNet-34 with standard middle fusion, no data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-34 + Middle Fusion (No Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (no augmentation)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=False,  # No augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-34 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet34',  # ResNet-34 instead of ResNet-18\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp3_resnet34_no_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet34_no_aug_results = train_resnet34_no_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eac883",
   "metadata": {},
   "source": [
    "### 3.2.2 Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e5d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING: ResNet-34 + Middle Fusion (With Augmentation)\n",
      "============================================================\n",
      "Loaded 2804 valid samples out of 2805\n",
      "Loaded 495 valid samples out of 495\n",
      "Model parameters: 43,088,897\n",
      "Training samples: 2804\n",
      "Validation samples: 495\n",
      "Learning rate: 0.0008\n",
      "Weight decay: 1e-06\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.61it/s, Loss=65703.4531] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 99124.6188\n",
      "Val Loss: 107322.5024\n",
      "MAE: 240.47\n",
      "\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.47it/s, Loss=81227.3125] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 92163.1452\n",
      "Val Loss: 70563.1094\n",
      "MAE: 189.04\n",
      "\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=65766.6562] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 79277.6088\n",
      "Val Loss: 62262.4773\n",
      "MAE: 179.65\n",
      "\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=42776.0312] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 64958.0558\n",
      "Val Loss: 75921.1836\n",
      "MAE: 202.48\n",
      "\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.68it/s, Loss=52520.8555] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 47652.4703\n",
      "Val Loss: 27046.1724\n",
      "MAE: 112.44\n",
      "\n",
      "Epoch 6/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.60it/s, Loss=37497.9062]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 35633.5909\n",
      "Val Loss: 44948.1774\n",
      "MAE: 152.45\n",
      "\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=15921.7324]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 28943.8791\n",
      "Val Loss: 25409.8503\n",
      "MAE: 109.18\n",
      "\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=44251.2031]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 23026.0490\n",
      "Val Loss: 20512.8347\n",
      "MAE: 103.17\n",
      "\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.59it/s, Loss=24961.2812]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 19919.7775\n",
      "Val Loss: 17823.4903\n",
      "MAE: 93.93\n",
      "\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.53it/s, Loss=10958.9531]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 18776.1287\n",
      "Val Loss: 19065.1475\n",
      "MAE: 94.96\n",
      "\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=11959.9941]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 17042.8688\n",
      "Val Loss: 28164.3819\n",
      "MAE: 113.20\n",
      "\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.59it/s, Loss=12711.7285]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15348.4762\n",
      "Val Loss: 15656.5202\n",
      "MAE: 82.92\n",
      "\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.42it/s, Loss=21801.0664]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14084.3811\n",
      "Val Loss: 15010.1869\n",
      "MAE: 83.01\n",
      "\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.66it/s, Loss=8133.9629] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14246.3937\n",
      "Val Loss: 14875.6891\n",
      "MAE: 87.88\n",
      "\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=8740.6484] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13632.3354\n",
      "Val Loss: 14886.5533\n",
      "MAE: 79.79\n",
      "\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.44it/s, Loss=11381.8145]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13038.1456\n",
      "Val Loss: 13794.5543\n",
      "MAE: 82.48\n",
      "\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.37it/s, Loss=17942.4883]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 15187.8177\n",
      "Val Loss: 32055.9642\n",
      "MAE: 123.19\n",
      "\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.58it/s, Loss=36162.6016]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 14826.7194\n",
      "Val Loss: 17379.2682\n",
      "MAE: 93.02\n",
      "\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.43it/s, Loss=11861.8438]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13144.0944\n",
      "Val Loss: 14248.9747\n",
      "MAE: 84.41\n",
      "\n",
      "Epoch 20/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=9118.6777] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13952.7637\n",
      "Val Loss: 13507.6129\n",
      "MAE: 77.29\n",
      "\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=21224.3145]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13972.1001\n",
      "Val Loss: 32404.5224\n",
      "MAE: 117.05\n",
      "\n",
      "Epoch 22/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=8671.5127] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13516.1525\n",
      "Val Loss: 30858.1169\n",
      "MAE: 114.47\n",
      "\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=9823.3320] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12994.4469\n",
      "Val Loss: 20585.9318\n",
      "MAE: 107.96\n",
      "\n",
      "Epoch 24/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:16<00:00,  5.43it/s, Loss=10844.4121]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11785.2529\n",
      "Val Loss: 23457.3118\n",
      "MAE: 116.36\n",
      "\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.52it/s, Loss=11628.8770]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12374.6989\n",
      "Val Loss: 13104.0104\n",
      "MAE: 81.99\n",
      "\n",
      "Epoch 26/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.50it/s, Loss=13174.1152]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13864.0507\n",
      "Val Loss: 13701.1168\n",
      "MAE: 77.02\n",
      "\n",
      "Epoch 27/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.54it/s, Loss=16515.8867]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12282.9718\n",
      "Val Loss: 16767.4535\n",
      "MAE: 85.84\n",
      "\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.62it/s, Loss=13672.0781]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11222.3651\n",
      "Val Loss: 11760.0813\n",
      "MAE: 74.16\n",
      "\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.51it/s, Loss=11469.0137]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11469.0313\n",
      "Val Loss: 12901.5543\n",
      "MAE: 77.10\n",
      "\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.63it/s, Loss=8778.0020] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 13145.7783\n",
      "Val Loss: 16580.6470\n",
      "MAE: 95.21\n",
      "\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=9461.3086] \n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11599.1675\n",
      "Val Loss: 12117.7284\n",
      "MAE: 76.53\n",
      "\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.64it/s, Loss=16782.4375]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 12341.5115\n",
      "Val Loss: 19674.3840\n",
      "MAE: 104.23\n",
      "\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.55it/s, Loss=22410.3828]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11471.6048\n",
      "Val Loss: 22065.4567\n",
      "MAE: 112.77\n",
      "\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=11226.2793]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10118.9804\n",
      "Val Loss: 12113.4151\n",
      "MAE: 74.36\n",
      "\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 87/87 [00:15<00:00,  5.57it/s, Loss=18005.9375]\n",
      "Validation: 100%|██████████| 16/16 [00:02<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10894.2290\n",
      "Val Loss: 30447.4351\n",
      "MAE: 115.17\n",
      "Early stopping triggered after 35 epochs\n",
      "Best epoch: 28\n",
      "\n",
      "Training completed!\n",
      "Best validation loss: 11760.0813\n",
      "\n",
      "Experiment completed! Results saved to: ../experiments/exp4_resnet34_with_aug_20251023_123711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### Experiment: ResNet-34 with Data Augmentation\n",
    "\n",
    "# Configuration for ResNet-34 with geometric augmentation\n",
    "def train_resnet34_with_aug():\n",
    "    \"\"\"Train ResNet-34 with standard middle fusion and geometric data augmentation\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"TRAINING: ResNet-34 + Middle Fusion (With Augmentation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create datasets (with augmentation for training)\n",
    "    train_dataset = Nutrition5KDataset(\n",
    "        csv_path=train_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='train',\n",
    "        augment=True,  # Enable geometric augmentation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5KDataset(\n",
    "        csv_path=val_csv,\n",
    "        data_root=DATA_ROOT,\n",
    "        split='val',\n",
    "        augment=False,  # Never augment validation\n",
    "        img_size=IMG_SIZE,\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    # Build model: ResNet-34 + Middle Fusion + Standard Regression Head\n",
    "    model = build_model(\n",
    "        encoder='resnet34',  # ResNet-34 instead of ResNet-18\n",
    "        fusion='middle',\n",
    "        regression_head='standard',\n",
    "        pretrained=False,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        fusion_channels=FUSION_CHANNELS,\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {model.get_num_parameters():,}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Loss function (calorie prediction only)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Hyperparameters for this experiment\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    \n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    print(f\"Weight decay: {weight_decay}\")\n",
    "    \n",
    "    steps_per_epoch = len(train_loader)\n",
    "    total_steps = NUM_EPOCHS * steps_per_epoch\n",
    "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "    # Learning rate scheduler: Warmup + Linear Decay\n",
    "    scheduler = get_warmup_cosine_scheduler(\n",
    "        optimizer, \n",
    "        warmup_steps=warmup_steps, \n",
    "        total_steps=total_steps,\n",
    "        min_lr_ratio=MIN_LR_RATIO\n",
    "    )\n",
    "    \n",
    "    # Create experiment directory\n",
    "    exp_name = f\"exp4_resnet34_with_aug_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    exp_dir = os.path.join(OUTPUT_DIR, exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        output_dir=exp_dir,\n",
    "        early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "        scheduler_step_on_batch=False\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "    \n",
    "    print(f\"\\nExperiment completed! Results saved to: {exp_dir}\")\n",
    "    return trainer.best_metrics\n",
    "\n",
    "# Run the experiment\n",
    "resnet34_with_aug_results = train_resnet34_with_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c355293",
   "metadata": {},
   "source": [
    "## Results Summary and Analysis\n",
    "\n",
    "Compare the results from different encoder architectures and the effect of data augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6a23373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENCODER EXPERIMENT RESULTS COMPARISON\n",
      "================================================================================\n",
      "Experiment                Val Loss   MAE        Best Epoch  \n",
      "--------------------------------------------------------------------------------\n",
      "ResNet-18 (No Aug)        9509.0767  63.78      35          \n",
      "ResNet-18 (With Aug)      10907.9683 73.49      23          \n",
      "ResNet-34 (No Aug)        9133.4005  66.62      33          \n",
      "ResNet-34 (With Aug)      11760.0813 74.16      28          \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare results from all encoder experiments\n",
    "def compare_encoder_results():\n",
    "    \"\"\"Compare results from all encoder experiments\"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ENCODER EXPERIMENT RESULTS COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Collect results (these variables should exist after running experiments)\n",
    "    results = [\n",
    "        (\"ResNet-18 (No Aug)\", resnet18_no_aug_results),\n",
    "        (\"ResNet-18 (With Aug)\", resnet18_with_aug_results),\n",
    "        (\"ResNet-34 (No Aug)\", resnet34_no_aug_results),\n",
    "        (\"ResNet-34 (With Aug)\", resnet34_with_aug_results)\n",
    "    ]\n",
    "    \n",
    "    # Display results in a table format\n",
    "    print(f\"{'Experiment':<25} {'Val Loss':<10} {'MAE':<10} {'Best Epoch':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for name, metrics in results:\n",
    "        val_loss = metrics['val_loss']\n",
    "        mae = metrics['mae']\n",
    "        epoch = metrics['epoch']\n",
    "        \n",
    "        print(f\"{name:<25} {val_loss:<10.4f} {mae:<10.2f} {epoch:<12}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "# Run the comparison\n",
    "compare_encoder_results()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
